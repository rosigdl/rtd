{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c526a7e",
   "metadata": {},
   "source": [
    "# Ch 4 Geometric Domains: the 5 Gs\n",
    "\n",
    "기하학적 도메인: 5G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f2dad",
   "metadata": {},
   "source": [
    "이 글의 주요 초점은 그래프, 격자, 그룹, 측지법(geodesics), 게이지(gauges)에 맞춰져 있습니다. 여기서 '그룹'이란 동질 공간에서의 전역 대칭 변환(global symmetry transformations)을, '측지'는 다양체(manifolds)의 도량형 구조(metric structures)를, '게이지'는 접선 다발(tangent bundles)(및 일반적으로 벡터 다발)에 정의된 국소 기준 프레임(local reference frames)을 의미합니다. 이러한 개념은 나중에 더 자세히 설명하겠습니다. 다음 섹션에서는 이러한 구조의 공통 요소와 주요 특징에 대해 자세히 논의하고 이와 관련된 대칭 그룹에 대해 설명하겠습니다. 사실 그리드는 그래프의 특수한 경우이므로 일반적인 순서로 설명하는 것이 아니라 기하학적 딥 러닝 청사진의 근간이 되는 중요한 개념을 강조하기 위해 설명하는 것입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ae32e29",
   "metadata": {},
   "source": [
    "## 4.1 그래프 및 세트\n",
    "\n",
    "사회학에서 입자 물리학에 이르기까지 다양한 과학 분야에서 그래프는 관계와 상호작용의 시스템 모델로 사용됩니다. 우리의 관점에서 그래프는 순열(permutations) 그룹으로 모델링되는 매우 기본적인 유형의 불변성(invariance)을 발생시킵니다. 또한 그리드나 집합과 같이 우리가 관심을 갖는 다른 객체도 그래프의 특정 사례로 얻을 수 있습니다.\n",
    "\n",
    "그래프 $\\mathcal{G = (V, E)}$는 노드 $\\mathcal{V}$와 노드 쌍 사이의 에지 $\\mathcal{E ⊆ V × V}$의 집합입니다. 다음 논의의 목적을 위해, 여기서는 노드에 모든 $u ∈ \\mathcal{V}$에 대해 $x_u$로 표시되는 s차원 노드 특징(features)이 부여된다고 가정하겠습니다. 소셜 네트워크는 가장 일반적으로 연구되는 그래프의 예로, 노드는 사용자를 나타내고 에지는 사용자 간의 친구 관계에 해당하며 노드 특징은 나이, 프로필 사진 등과 같은 사용자 속성을 모델링하는 것으로 알려져 있습니다. 에지 또는 전체 그래프에 특징을 부여하는 것도 종종 가능하지만, 이 섹션의 주요 결과를 변경하지 않으므로 이에 대한 논의는 향후 작업으로 미루겠습니다.\n",
    "\n",
    ">애플리케이션 분야에 따라 노드는 정점(vertices)이라고도 하며, 에지는 링크 또는 관계라고도 합니다. 다음 용어는 같은 의미로 사용됩니다.\n",
    "\n",
    ">동형(Isomorphism)은 두 그래프 사이의 에지 보존 바이제션입니다. 여기에 표시된 두 개의 동형 그래프는 노드의 재정렬까지 동일합니다.\n",
    "\n",
    "그래프의 핵심 구조적 특성은 일반적으로 V의 노드가 특정 순서로 제공되지 않는다고 가정하므로 그래프에서 수행되는 모든 연산은 노드의 순서에 의존해서는 안 된다는 것입니다. 따라서 그래프에 작용하는 함수가 만족해야 하는 바람직한 속성은 순열 불변성(permutation invariance)이며, 이는 두 개의 동형(isomorphic) 그래프에 대해 이러한 함수의 결과가 동일하다는 것을 의미합니다. 여기서 도메인 $Ω = \\mathcal{G}$와 공간 $\\mathcal{X (G},$ $\\mathbb{R}^d)$는 d차원 노드별 신호의 공간으로, 이를 청사진의 특정 설정으로 볼 수 있습니다. 우리가 고려하는 대칭은 순열 그룹(permutation group) $\\mathcal{G} = \\sum_{n}$에 의해 주어지며, 그 요소는 노드 인덱스 집합 $\\left\\{1, ... . , n \\right\\}$.\n",
    "\n",
    "먼저 가장자리가 없는 그래프(즉, $\\mathcal{E} = ∅$)의 특수한 경우인 집합에 대한 순열 불변성 개념을 설명하겠습니다. 노드 특징을 $n × d$ 행렬 $X = (x_1, . . . , x_n)^{T}$ 의 행으로 쌓아 올리면 노드의 순서를 효과적으로 지정할 수 있습니다. 노드 집합에 대한 순열 $\\mathfrak{g} ∈ Σ_n$의 작용은 $X$의 행을 재배열하는 것으로, 각 행과 열에 정확히 하나의 1이 포함되고 다른 모든 항목은 0인 $n×n$ 순열 $ρ(\\mathfrak{g}) = P$로 나타낼 수 있습니다.\n",
    "\n",
    ">이러한 순열은 정확히 n! 개가 있으므로 $Σ_n$은 적당한 $n$이라 할지라도 매우 큰 그룹입니다. \n",
    "\n",
    "그런 다음 이 집합에서 작동하는 함수 f는 이러한 순열 행렬 P에 대해 f(PX) = f(X)를 유지하면 순열 불변성이라고 합니다. 이러한 간단한 함수 중 하나는 다음과 같습니다.\n",
    "\n",
    "$$\n",
    "f(X) = \\phi\\left( \\sum_{u∈V} ψ (x_u)\\right) \\tag{6}\n",
    "$$\n",
    "\n",
    "여기서 함수 $ψ$는 모든 노드의 특징에 독립적으로 적용되고 $\\phi$는 합산된(sum-aggregated) 출력에 적용됩니다. 합은 입력이 제공되는 순서와 무관하므로 이러한 함수는 노드 집합의 순열에 대해 불변이므로 노드가 어떻게 순열되더라도 항상 동일한 출력을 반환하도록 보장됩니다.\n",
    "\n",
    "위와 같은 함수는 그래프 단위의 '전역' 출력을 제공하지만, 노드 단위로 '로컬'로 작동하는 함수에 관심이 있을 때가 많습니다. 예를 들어, 모든 노드의 특징을 업데이트하는 함수를 적용하여 잠재 노드 특징 집합을 얻고 싶을 수 있습니다. 이러한 잠재 노드 특징을 행렬 $H = F(X)$에 쌓으면 더 이상 순열 불변이 아니므로, $H$의 행 순서를 $X$의 행 순서와 연결해야 어떤 출력 노드 특징이 어떤 입력 노드에 해당하는지 알 수 있습니다. 대신 입력의 순열을 \"커밋(commit)\"하면 결과 객체를 일관되게 순열한다는 순열 동등성(permutation equivariance)에 대한 보다 세분화된 개념이 필요합니다. 공식적으로, 어떤 순열 행렬 $P$에 대해 $F(X)가 F(PX) = PF(X)$를 만족하면 순열 등변수(permutation equivariant) 함수입니다. 공유 노드 단위 선형 변환\n",
    "\n",
    "$$\n",
    "    FΘ(X) = XΘ \\tag{7}\n",
    "$$\n",
    "\n",
    "은 가중치 행렬 $Θ ∈ \\mathbb{R}^{d×d'}$ 으로 지정된 값은 이러한 순열 등변수 함수의 한 가지 가능한 구성으로, 예제에서는 $h_u = Θ^T x_u$ 형식의 잠재 특징을 생성합니다. \n",
    "\n",
    ">함수 $F(X)$에 굵은 표기법을 사용하여 노드 단위 벡터 특징을 출력하므로 행렬 값 함수라는 점을 강조했습니다.\n",
    "\n",
    "이 구조는 기하학적 딥 러닝 청사진에서 자연스럽게 발생합니다. 먼저 선형 동등함수($FPX = PFX$ 형식의 함수)를 특성화하려고 시도할 수 있는데, 이러한 지도는 두 개의 생성기, 즉 동일성 $F_1 X = X$와 평균 $F_2 X = \\frac{1}{n} 11^{\\intercal} X = \\frac{1}{n} \\sum_{u=1}^{n} x_u$의 선형 조합으로 작성할 수 있음을 쉽게 검증할 수 있습니다. 5.4절에서 설명하겠지만, 널리 사용되는 딥셋(Deep Sets) 아키텍처는 정확히 이 청사진을 따릅니다(Zaheer et al., 2017).\n",
    "\n",
    "이제 순열 불변성과 동등성의 개념을 집합에서 그래프로 일반화할 수 있습니다. 일반적인 설정 $\\varepsilon \\neq \\emptyset$에서 그래프 연결성은 다음과 같이 정의되는 $n × n$ 인접(adjacency) 행렬 A로 나타낼 수 있습니다.\n",
    "\n",
    "$$\n",
    "a_{uv} = \\begin{align}  \\tag{8}\n",
    "        \\begin{cases}\n",
    "        1& (u,v) ∈ \\varepsilon \\\\ \n",
    "        0& \\text{otherwise.} \n",
    "        \\end{cases} \n",
    "        \\end{align}\n",
    "$$\n",
    ".\n",
    "\n",
    ">그래프가 방향이 없는(undirected) 경우, 즉 $(v, u)$ 가 $\\varepsilon$ 이면 $(u, v) ∈ \\varepsilon$ 인 경우 인접 행렬은 대칭(symmetric)이며 $A = A^{\\intercal}$ 입니다.\n",
    "\n",
    "이제 인접성 및 특징 행렬 $A$와 $X$는 \"동기화\"되어 있는데, 이는 $a_uv$가 $X$의 $u$번째 행과 $v$번째 행으로 설명되는 노드 간의 인접성 정보를 지정한다는 의미에서그렇습니다. 따라서 노드 특징 $X$에 순열 행렬 $P$를 적용하는 것은 자동으로 $A$의 행과 열에 적용하는 것을 의미하며, $PAP^{\\intercal}$가 됩니다. 다음과 같은 경우 (그래프 단위의 함수) f는 순열 불변성(permutation invariant)이라고 합니다.\n",
    "\n",
    "$$\n",
    "f(\\mathbf{PX}, \\mathbf{PAP}^{\\intercal}) = f(\\mathbf{X, A}) \\tag{9}\n",
    "$$\n",
    "\n",
    "그리고 (노드 단위 함수) $\\mathbf{F}$는 모든 순열 행렬 $\\mathbf{P}$에 대해 다음과 같은 경우 순열 등변수(permutation equivariant)입니다.\n",
    "\n",
    "$$\n",
    "\\mathbf{F}(\\mathbf{PX}, \\mathbf{PAP}^{\\intercal}) = \\mathbf{PF}(\\mathbf{X, A}) \\tag{10}\n",
    "$$\n",
    ".\n",
    "\n",
    ">$PAP^{\\intercal}$는 행렬에 작용하는 $\\sum_n$의 표현입니다.\n",
    "\n",
    ">그래프 위에서 작동하는 함수가 이제 인접성 정보를 고려해야 한다는 사실을 강조하기 위해 $f(\\mathbf{X, A})$라는 표기법을 사용합니다.\n",
    "\n",
    "여기서도 선형 등변수 함수를 먼저 특성화할 수 있습니다. Maron 등(2018)이 관찰한 바와 같이, 방정식 (10)을 만족하는 모든 선형 $\\mathbf{F}$는 15개의 선형 제너레이터의 선형 조합으로 표현할 수 있으며, 놀랍게도 이 제너레이터 제품군(family of generators)은 $n$과 무관합니다. 이러한 제너레이터 중에서 특히 우리의 청사진은 로컬 제너레이터, 즉 노드 $u$의 출력이 그래프에서 인접 노드에 직접적으로 의존하는 제너레이터를 선호합니다. 한 노드가 다른 노드에 이웃한다는 것이 무엇을 의미하는지 정의함으로써 모델 구성에서 이 제약 조건을 명시적으로 공식화할 수 있습니다.\n",
    "\n",
    ">이는 인접 행렬에 작용하는 선형 맵을 인덱싱하는 4-인덱스 $(u, v),(u', v')$로 주어진 4개의 요소 집합을 분할하는 방법의 수를 세는 벨 번호(Bell number) $B_4$에 해당합니다.\n",
    "\n",
    "1-홉(1-hop)이라고도 하는 노드 $u$의 (방향성 없는) 이웃은 다음과 같이 정의됩니다.\n",
    "\n",
    "$$\n",
    "    \\mathcal{N}_u = \\{v : (u, v) ∈ \\varepsilon \\text{ or } (v, u) ∈ \\varepsilon \\} \\tag{11}\n",
    "$$\n",
    "\n",
    "및 이웃 기능(neighbourhood features)을 다중 집합으로 지정합니다.\n",
    "\n",
    "$$\n",
    "    \\mathbf{X}_{\\mathcal{N}_u} = \\{\\{x_v : v ∈ \\mathcal{N}_u \\}\\}. \\tag{12}\n",
    "$$\n",
    "\n",
    "1홉 이웃에 대한 작업은 청사진의 로컬리티 측면, 즉 그래프에 대한 메트릭을 $\\varepsilon$의 에지를 사용하여 노드 간의 최단 경로 거리로 정의하는 것과 잘 일치합니다.\n",
    "\n",
    ">종종 노드 $u$ 자체는 자체 이웃에 포함됩니다.\n",
    "\n",
    ">다중 집합 $\\{\\{ . . . \\}\\}$로 표시되는 다중 집합은 동일한 요소가 두 번 이상 나타날 수 있는 집합입니다. 여기서는 서로 다른 노드의 특징이 같을 수 있기 때문에 이런 경우가 해당됩니다.\n",
    "\n",
    "따라서 GDL 청사진은 노드와 그 이웃의 특징에 대해 작동하는 로컬 함수 $\\phi$를 지정하여 그래프에서 순열 등식 함수를 구성하는 일반적인 방법을 도출합니다 $(\\phi(x_u, \\mathbf{X}_{\\mathcal{N}_u} ))$. 그런 다음 모든 노드의 이웃에 $\\varepsilon$를 개별적으로 적용하여 순열 등변수 함수 $\\mathbf{F}$를 구성할 수 있습니다(그림 10 참조):\n",
    "\n",
    "$$\n",
    "\\begin{align}\\tag{13}\n",
    "\\mathbf{F(X, A)} =  \\begin{bmatrix}  \n",
    "- & \\phi(x_1, \\mathbf{X}_{\\mathcal{N}_u} ) & - \\\\\n",
    "- & \\phi(x_1, \\mathbf{X}_{\\mathcal{N}_u} ) & -\\\\\n",
    "& \\vdots & \\\\\n",
    "- & \\phi(x_1, \\mathbf{X}_{\\mathcal{N}_u} ) & - \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$\\mathbf{F}$는 공유 함수 $\\phi$를 각 노드에 로컬로 적용하여 구성되므로, 그 순열 등식은 $\\phi$의 출력이 $\\mathcal{N}_u$의 노드 순서에 독립적이라는 것에 달려 있습니다. 따라서 $\\phi$가 순열 불변으로 구축되면 이 속성은 충족됩니다. 향후 작업에서 살펴보겠지만 $\\phi$의 선택은 이러한 체계의 표현력에 결정적인 역할을 합니다. $\\phi$가 주입적(injective)일 때, 이는 반복적인 색상 정제 절차를 통해 두 그래프가 동형화되기 위한 필수 조건을 제공하는 그래프 이론의 고전적인 알고리즘인 Weisfeiler-Lehman 그래프 동형성 테스트(Weisfeiler-Lehman graph isomorphism test)의 한 단계와 동일합니다.\n",
    "\n",
    "이 예제에서 집합(set)에 정의된 함수와 보다 일반적인 그래프에 정의된 함수의 차이점은 후자의 경우 도메인의 구조를 명시적으로 설명해야 한다는 점입니다. 결과적으로 그래프는 머신 러닝 문제에서 도메인이 입력의 일부(part of the input)가 되는 반면, 집합(set)과 그리드(grids)(둘 다 그래프의 특정 경우임)를 다룰 때는 특징(features)만 지정하고, 도메인은 고정되어 있다고 가정할 수 있다는 점에서 차이가 있습니다. 이 차이점은 앞으로의 논의에서 반복되는 모티브가 될 것입니다. 결과적으로 기하학적 안정성(도메인 변형에 대한 불변성(invariance))이라는 개념은 그래프에 대한 대부분의 학습 문제에서 매우 중요합니다. 순열 불변(permutation invariant) 함수와 등변 함수(equivariant functions)가 동형(위상적((topologically)으로 동등한) 그래프에서 동일한 출력을 생성한다는 것은 우리의 구성에서 곧바로 따라옵니다. 이러한 결과는 거의 동형(isomorphic) 그래프로 일반화할 수 있으며, 그래프 섭동(perturbations) 하에서의 안정성에 대한 몇 가지 결과가 존재합니다(Levie et al., 2018). 우리는 이러한 불변성을 더 자세히 연구하기 위한 수단으로 사용할 다양체에 대한 논의에서 이 중요한 점으로 돌아갈 것입니다. \n",
    "\n",
    "둘째, 그래프와 그리드는 추가 구조로 인해 집합과 달리 사소하지 않은 방식으로 거칠게(coarsened) 처리할 수 있어 다양한 풀링 작업을 수행할 수 있습니다.\n",
    "\n",
    ">더 정확히 말하자면, 집합 구조만을 가정한 비사소한 조악화(coarsening)를 정의할 수는 없습니다. 정렬되지 않은 집합으로부터 위상 구조를 추론하는 기존 접근 방식이 존재하며, 이러한 접근 방식은 비사소한 조악화를 인정할 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a0272d0",
   "metadata": {},
   "source": [
    "## 4.2 그리드와 유클리드 공간 \n",
    "\n",
    "두 번째로 고려하는 객체 유형은 그리드입니다. 딥러닝의 영향은 컴퓨터 비전, 자연어 처리, 음성 인식 분야에서 특히 극적이었다고 해도 과언이 아닙니다. 이러한 애플리케이션은 모두 기본 그리드 구조라는 기하학적 공통 분모를 공유합니다. 이미 언급했듯이 그리드는 특수한 인접성을 가진 그래프의 특별한 경우입니다. 그러나 그리드의 노드 순서는 고정되어 있기 때문에 그리드에 정의된 신호에 대한 머신러닝 모델은 더 이상 순열 불변성(permutation invariance)을 고려할 필요가 없으며, 더 강력한 기하학적 선행 조건인 변환 불변성(translation invariance)을 갖습니다.\n",
    "\n",
    "### 순환 행렬 및 컨볼루션 \n",
    "Circulant matrices and Convolutions\n",
    "\n",
    "이 점에 대해 좀 더 자세히 살펴보겠습니다. 간단히 주기적 경계 조건을 가정하면, 1차원 그리드는 노드의 색인이 $0, 1, . . . , n-1$ 모듈로 $n$ (표기 간결성을 위해 생략하겠습니다)으로 인덱싱된 노드와 $a_{u,u+1 \\text{ mod } n} = 1 $, 그렇지 않으면 0인 요소를 가진 인접(adjacency) 행렬로 생각할 수 있습니다. 앞서 설명한 일반적인 그래프의 경우와 크게 두 가지 차이점이 있습니다. 첫째, 각 노드 $u$는 이웃 노드 $u - 1$ 및 $u + 1$에 대해 동일한 연결성을 가지므로 구조적으로 다른 노드와 구별할 수 없습니다. 둘째, 더 중요한 것은 그리드의 노드 순서가 고정되어 있기 때문에 이웃 노드들의 순서도 고정되어 있다는 것입니다. 즉, $u - 1$을 '왼쪽 이웃'이라 부르고 $u + 1$을 '오른쪽 이웃'이라 부를 수 있습니다. 국부 집계 함수 $\\phi$를 사용하여 등변 함수 $\\mathbf{F}$를 설계하는 이전 방법을 사용하면 그리드의 모든 노드에서 $f(\\mathbf{x}_u) = \\phi(\\mathbf{x}_{u-1}, \\mathbf{x}_{u}, \\mathbf{x}_{u+1})$가 됩니다. 이제 $\\phi$는 더 이상 순열 불변일 필요가 없습니다. 선형 변환 $\\phi(\\mathbf{x}_{u-1}, \\mathbf{x}_u, \\mathbf{x}_{u+1}) = \\theta_{-1} \\mathbf{x}_{u-1} + \\theta_0 \\mathbf{x}_u + \\theta_1 \\mathbf{x}_{u+1}$의 특정 선택의 경우, $\\mathbf{F(X)}$를 행렬 곱으로 쓸 수 있습니다,\n",
    "\n",
    ">나중에 살펴보겠지만 그리드를 균질한 공간으로 만듭니다.\n",
    "\n",
    "$$\n",
    "\\mathbf{F(X)} =  \\begin{bmatrix} \n",
    "\\theta_{0} & \\theta_{1} & & & \\theta_{-1} \\\\\n",
    "\\theta_{-1} & \\theta_{0} & \\theta_{1} & & \\\\\n",
    "            & \\ddots & \\ddots &\\ddots &  \\\\\n",
    "            & & \\theta_{-1} & \\theta_{0} & \\theta_{1} \\\\\n",
    "\\theta_{1} & & & \\theta_{-1} & \\theta_{-1} \\\\\n",
    "\\end{bmatrix}\\begin{bmatrix} - & x_0 & - \\\\\n",
    "                             - & x_1 & - \\\\\n",
    "                              & \\vdots & \\\\\n",
    "                            - & x_{n-2} & - \\\\\n",
    "                            - & x_{n-1} & - \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "각 대각선을 따라 하나의 요소가 반복되는 매우 특별한 다중 대각선 구조에 주목하세요. 머신 러닝 문헌에서는 이를 \"가중치 공유(weight sharing)\"라고 부르기도 합니다. \n",
    "\n",
    "보다 일반적으로 벡터 $\\theta = (\\theta_0, . . . , \\theta_{n-1})$이 주어지면 순환 행렬(circulant matrix) $\\mathbf{C}(\\theta) = (\\theta_{u-v \\text{ mod } n})$은 벡터 $\\theta$의 원형으로 이동된 버전을 추가하여 구할 수 있습니다. 순환 행렬은 이산 컨볼루션과 동의어로, \n",
    "\n",
    "$$\n",
    "    (\\mathbf{x} \\bigstar \\theta)_u = \\sum_{v=0}^{n-1} x_{v \\text{ mod } n} \\theta_{u−v \\text{ mod } n}\n",
    "$$\n",
    "\n",
    "$\\mathbf{C}(\\theta)\\mathbf{x} = \\mathbf{x} \\bigstar \\theta$를 갖기 때문입니다. $\\theta = (0, 1, 0, ... , 0)^{\\intercal}$을 선택하면 벡터를 한 위치 오른쪽으로 이동시키는 특수 순환 행렬이 생성됩니다. 이 행렬을 (오른쪽) 시프트(shift) 또는 변환 연산자(translation operator)라고 하며 $\\mathbf{S}$로 표시합니다.\n",
    "\n",
    ">주기적인 경계 조건으로 인해, 원형 또는 순환 컨볼루션입니다. 신호 처리에서 $\\theta$는 종종 '필터'라고 불리며, CNN에서는 그 계수를 학습할 수 있습니다.\n",
    "\n",
    ">왼쪽 시프트 연산자는 $\\mathbf{S}^{\\intercal}$로 표시됩니다. 분명히 왼쪽에서 오른쪽으로(또는 그 반대로) 이동해도 아무 작업도 수행하지 않으므로 S는 직교(orthogonal)입니다: $\\mathbf{S}^{\\intercal}\\mathbf{S} = \\mathbf{S\\mathbf{S}^{\\intercal} = \\mathbf{I}}$\n",
    "\n",
    "순환 행렬은 순환성(commutativity) 속성으로 특징 지을 수 있습니다. 순환 행렬의 곱은 모든 $\\theta$와 $η$에 대해 $\\mathbf{C}(\\theta)\\mathbf{C}(η) = \\mathbf{C}(η)\\mathbf{C}(\\theta)$로, 순환 행렬의 곱은 정류성입니다. 시프트는 순환 행렬이므로 컨볼루션 연산자의 익숙한 변환(translation) 또는 시프트 등식(shift equivariance)을 얻을 수 있습니다,\n",
    "\n",
    "$$\n",
    "    \\mathbf{SC(\\theta)x = C(\\theta)Sx}\n",
    "$$\n",
    "\n",
    "\n",
    "기본 대칭 그룹(변환 그룹)이 아벨리안(Abelian)이기 때문에 이러한 순환성 특성은 놀랄 일이 아닙니다. 또한, 그 반대 방향도 참인 것처럼 보입니다. 즉, 행렬이 이동과 함께 움직인다면 행렬은 순환적입니다. 이를 통해 컨볼루션을 변환 등변량(translation equivariant) 선형 연산으로 정의할 수 있으며, 이는 기하학적 선행의 힘과 기하학적 ML의 전반적인 철학인 변환 대칭(translational symmetry)의 첫 번째 원리에서 컨볼루션이 나온다는 것을 잘 보여줍니다.\n",
    "\n",
    "집합과 그래프의 상황과 달리 선형적으로 독립적인 이동 등변수 함수(linearly\n",
    "independent shift-equivariant functions)(컨볼루션)의 수는 영역의 크기에 따라 증가합니다(순환 행렬의 각 대각선에는 하나의 자유도가 있기 때문입니다). 그러나 컨볼루션 신경망 아키텍처 구현에서 이러한 원리를 사용하는 방법을 5.1절에서 설명할 때 확인할 수 있듯이, 스케일 분리 사전(prior)은 필터가 국소적일 수 있으므로 계층당 $Θ(1)$-파라미터 복잡도가 동일함을 보장합니다.\n",
    "\n",
    "### 이산 푸리에 변환의 유도\n",
    "Derivation of the discrete Fourier transform\n",
    "\n",
    "푸리에 변환과 컨볼루션과의 관계에 대해서는 이미 언급했습니다. 푸리에 변환이 컨볼루션 연산을 대각선화한다는 사실은 신호 처리에서 푸리에 변환의 요소별(element-wise) 곱으로 주파수 영역에서 컨볼루션을 수행하는 데 사용되는 중요한 속성입니다. 그러나 교과서에서는 일반적으로 이 사실만 언급할 뿐 푸리에 변환의 출처와 푸리에 기저의 특별한 점에 대해서는 거의 설명하지 않습니다. 여기에서는 대칭의 기본 원리가 얼마나 기초적인지 다시 한 번 보여줄 수 있습니다.\n",
    "\n",
    "이를 위해 선형 대수학에서 (대각화 가능한) 행렬은 상호 통근(commute)하는 경우 결합 대각화(joinly diagonalisable)가 가능하다는 사실을 기억해 두세요. 즉, 모든 순환 행렬에는 고유값(eigenvalues)만 다른 공통의 고유 기저(eigenbasis)가 존재합니다. 따라서 우리는 하나의 순환 행렬을 선택하고 그 행렬의 고유 벡터를 계산할 수 있으며, 다른 모든 순환 행렬의 고유 벡터도 계산할 수 있습니다. 고윳값이 이산 푸리에 기저(discrete Fourier basis)가 되는 시프트 연산자를 선택하면 편리합니다.\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PFDu9oVAE-g\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n",
    "\n",
    "$$\n",
    "\\varphi_k = \\frac{1}{\\sqrt{n}} ( 1, e^{\\frac{2πik}{n}}, e^{\\frac{4πik}{n}}, \\ldots , e^{\\frac{2πi(n-1)k}{n}})^{\\intercal} , \\hspace{1 cm} k = 0, 1, \\ldots, n-1\n",
    "$$\n",
    "\n",
    "를 $n × n$ 푸리에 행렬 $\\Phi = (\\varphi_0, ... , \\varphi_{n-1})$로 배열할 수 있습니다. $\\Phi^{*}$를 곱하면 이산 푸리에 변환(DFT)이 되고, $\\Phi$를 곱하면 역 DFT가 됩니다,\n",
    "\n",
    "$$\n",
    "    \\hat{x}_k = \\frac{1}{\\sqrt{n}}\\sum_{u=0}^{n-1} x_u e^{-\\frac{2πiku}{n}}\n",
    "    \\quad\n",
    "    \\hat{x}_u = \\frac{1}{\\sqrt{n}}\\sum_{k=0}^{n-1} \\hat{x}_k e^{+\\frac{2πiku}{n}}\n",
    "$$\n",
    ".\n",
    "\n",
    ">고유값(eigenvalues)을 추가로 가정해야 하며, 그렇지 않으면 대각선이 여러 개 있을 수 있습니다. 이 가정은 우리가 선택한 S로 만족됩니다.\n",
    "\n",
    ">S는 직교하지만 대칭이 아니므로 고유 벡터(eigenvectors)는 직교하지만 고유값은 복소(complex)합니다(통일의 근(roots of unity)).\n",
    "\n",
    ">고유 벡터는 복소하므로 $\\Phi$를 전치(transposing)할 때 복소 접합(complex conjugation)을 취해야 합니다.\n",
    "\n",
    "모든 순환 행렬은 공동으로 대각선화 가능하기(jointly diagonalisable) 때문에 푸리에 변환에 의해 대각선화되며 고유값만 다릅니다. 순환 행렬 $\\mathbf{C(\\theta)}$의 고유값은 필터의 푸리에 변환이므로(예: Bamieh (2018) 참조), $\\hat{\\theta} = \\Phi^{*} \\theta$이므로 컨볼루션 정리를 구할 수 있습니다:\n",
    "\n",
    "$$\n",
    "    \\mathbf{C(\\theta)x} = \\Phi \\begin{bmatrix} \n",
    "\\hat{\\theta_{0}} & & \\\\\n",
    "                 & \\ddots & \\\\\n",
    "                 & & \\hat{\\theta_{n-1}}  \\\\\n",
    "\\end{bmatrix} \\Phi^{*} x = \\Phi (\\hat{\\theta} \\odot \\hat{x} )\n",
    "$$\n",
    ".\n",
    "\n",
    ">푸리에 변환은 직교 행렬 $(\\Phi^{*}\\Phi= \\mathbf{I})$ 이므로 기하학적으로 n차원 회전에 해당하는 좌표계의 변화로 작용합니다. 이 좌표계(\"푸리에 영역\")에서 순환 $\\mathbf{C}$ 행렬의 작용은 원소별 곱이 됩니다.\n",
    "\n",
    "푸리에 행렬 $\\Phi$는 특수한 대수 구조를 가지고 있기 때문에 고속 푸리에 변환(FFT) 알고리즘을 사용하여 $\\Phi^{\\star}\\mathbf{x}$와 $\\Phi \\mathbf{x}$의 곱을 $\\mathcal{O}(n \\log n)$의 복잡도로 계산할 수 있습니다. 이는 신호 처리에서 주파수 도메인 필터링이 널리 사용되는 이유 중 하나이며, 또한 필터는 일반적으로 주파수 도메인에서 직접 설계되므로 푸리에 변환 $\\hat{\\theta}$을 명시적으로 계산하지 않습니다.\n",
    "\n",
    "여기서 살펴본 푸리에 변환과 컨볼루션의 도출은 교훈적인 가치 외에도 이러한 개념을 그래프로 일반화할 수 있는 체계를 제공합니다. 고리 그래프의 인접 행렬이 정확히 시프트 연산자라는 것을 깨닫게 되면, 인접 행렬의 고유 벡터를 계산하여 그래프 푸리에 변환과 컨볼루션 연산자의 유추를 개발할 수 있습니다(예: Sandryhaila and Moura (2013) 참조). '스펙트럼 GNN(spectral GNNs)'이라고도 불리는 CNN과 유사하게 그래프 신경망을 개발하려는 초기 시도는 바로 이 청사진을 활용했습니다. 4.4-4.6절에서 이 비유에는 몇 가지 중요한 한계가 있음을 살펴보겠습니다. 첫 번째 한계는 그리드가 고정되어 있기 때문에 그리드의 모든 신호가 동일한 푸리에 기준으로 표현될 수 있다는 사실에서 비롯됩니다. 반면 일반 그래프에서 푸리에 기저는 그래프의 구조에 따라 달라집니다. 따라서 서로 다른 두 그래프의 푸리에 변환을 직접 비교할 수 없으며, 이는 머신 러닝 문제에서 일반화가 부족하다는 의미로 해석할 수 있는 문제입니다. 둘째, 1차원 그리드의 텐서 곱으로 구성된 다차원 그리드는 푸리에 기저 요소와 해당 주파수(고유값)를 여러 차원으로 구성할 수 있는 기본 구조를 유지합니다. 예를 들어 이미지에서 우리는 자연스럽게 수평 및 수직 주파수에 대해 이야기할 수 있으며 필터에는 방향이라는 개념이 있습니다. 그래프에서는 푸리에 기저 함수를 해당 주파수의 크기로만 구성할 수 있기 때문에 푸리에 영역의 구조는 1차원입니다. 따라서 그래프 필터는 방향이나 등방성(isotropic)을 인식하지 못합니다. \n",
    "\n",
    ">그래프 신호 처리에서 그래프 푸리에 변환을 구성하기 위해 인접 행렬의 대안으로 그래프 라플라시안(graph Laplacian)의 고유 벡터를 사용하는 경우가 많습니다(Shuman et al. (2013) 참조). 그리드에서는 두 행렬 모두 공동 고유 벡터를 갖지만 그래프에서는 관련 구조가 있지만 다소 다른 결과를 가져옵니다.\n",
    "\n",
    "### 연속 푸리에 변환의 유도\n",
    "Derivation of the continuous Fourier transform\n",
    "\n",
    "완전성을 위해, 그리고 다음 논의를 위한 단초로, 연속 설정에서 분석을 반복합니다. 3.4절에서와 같이 $Ω = \\mathbb{R}$에 정의된 함수와 $f$를 어떤 위치 $v$만큼 이동시키는 변환 연산자 $(S_vf)(u) = f(u - v)$를 고려합니다. 푸리에 기저 함수 $\\varphi_ξ(u) = e^{iξu}$에 $S_v$를 적용하면 지수의 연관성에 의해 지수가 산출됩니다,\n",
    "\n",
    "$$\n",
    "    S_ve^{iξu} = e^{iξ(u-v)} = e^{-iξv}e^{iξu}\n",
    "$$\n",
    "\n",
    "즉, $\\varphi_ξ(u)$는 $S_v$의 복소 고유벡터(complex eigenvector)이며 복소 고유값은 $e^{-iξv}$로, 이산 설정에서와 똑같은 상황입니다. $S_v$는 단일 연산자이므로(즉, 모든 $p$와 $x ∈ L_p(\\mathbb{R})$에 대해 $\\|S_vx\\|_p = \\|x\\|_p$ 모든 고유값 $λ$는 $|λ| = 1$을 만족해야 하며, 이는 위에서 찾은 고유값 $e^{-iξv}$와 정확히 일치합니다. 또한 변환 연산자의 스펙트럼은 단순하므로 동일한 고유값을 공유하는 두 함수는 반드시 선형이어야 합니다. 실제로 어떤 $ξ_0$에 대해 $S_vf = e^{-iξ_0vf}$라고 가정해 보겠습니다. 양쪽에서 푸리에 변환을 취하면 다음을 얻을 수 있습니다. \n",
    "\n",
    "$$\n",
    "    ∀ ξ , e^{-iξv} \\hat{f}(ξ) = e^{-iξ_0v}\\hat{f}(ξ) ,\n",
    "$$\n",
    "\n",
    "\n",
    "는 $\\hat{f}(ξ)= 0$ 인 경우 $\\hat{f}(ξ) = 0$ 이므로 $f = α\\varphiξ_0$ 입니다.\n",
    "\n",
    "변환 등변수인 일반 선형 연산자 $C$의 경우 $(S_vC = CS_v)$, 다음과 같습니다.\n",
    "\n",
    "$$\n",
    "    S_vCe^{iξu} = CS_ve^{iξu} = e^{iξv}Ce^{iξu},\n",
    "$$\n",
    "\n",
    "\n",
    "는 $Ce^{iξu}$가 또한 고유값 $e^{-iξv}$ 를 갖는 $S_v$의 고유 함수임을 의미하며, 스펙트럼의 단순성으로부터 $Ce^{iξu} = β\\varphiξ(u)$; 즉 푸리에 기저가 모든 변환 등변수 연산자의 고유 기저라는 것을 알 수 있습니다. 결과적으로 $C$는 푸리에 영역에서 대각선이며 $Ce^{iξu} = \\hat{p}C(ξ)e^{iξu}$로 표현할 수 있으며, 여기서 $\\hat{p}C(ξ)$ 는 다른 주파수 $ξ$에 작용하는 전달 함수(transfer function )입니다. 마지막으로, 임의의 함수 $x(u)$의 경우 선형성에 의해,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "(Cx)(u) & = C \\int_{-∞}^{+∞} \\hat{x}(ξ)e^{iξu}dξ \\\\\n",
    "& = \\int_{-∞}^{+∞} \\hat{x}(ξ)\\hat{p}_C(ξ)e^{iξu}dξ \\\\\n",
    "& =  \\int_{-∞}^{+∞} p_C(v)x(u − v)dv \\\\\n",
    "& = (x \\star p_C)(u),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "여기서 $p_C(u)$는 $\\hat{p}_C(ξ)$의 역 푸리에 변환입니다. 따라서 모든 선형 변환 등식 연산자는 컨볼루션입니다.\n",
    "\n",
    ">고유함수는 '고유벡터'와 동의어로, 연속 연산자의 고유벡터를 나타낼 때 사용됩니다.\n",
    "\n",
    ">번역 그룹( translation group)의 스펙트럼 특성화는 함수 분석의 보다 일반적인 결과인 스톤의 정리(Stone’s Theorem)의 특정 사례로, 모든 단일 매개변수 단일 그룹(one-parameter unitary group)에 대해 동등한 특성(equivalent characterisation)을 도출합니다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51895251",
   "metadata": {},
   "source": [
    "## 4.3 그룹 및 동질 공간 \n",
    "Groups and Homogeneous spaces\n",
    "\n",
    "그리드에 대한 논의에서 시프트와 컨볼루션이 어떻게 밀접하게 연결되어 있는지 강조했습니다. 컨볼루션은 선형 시프트 등변수(linear shift-equivariant) 연산이며, 그 반대로도, 시프트 등변수 선형(shift-equivariant linear) 연산자는 모두 컨볼루션입니다. 또한 시프트 연산자는 푸리에 변환에 의해 공동으로 대각선화될 수 있습니다. 컨볼루션과 푸리에 변환은 모두 합하거나 적분할 수 있는 *모든 대칭 그룹*에 대해 정의할 수 있습니다. \n",
    "\n",
    ">엄밀히 말하면, 좌변수 하르(Haar) 측정값이 존재하도록 군이 국소적으로 콤팩트해야 합니다. 이 측정값에 대해 적분하면, 함수 $x : \\mathbb{R} → \\mathbb{R}$에 대해 $\\sum_{-∞}^{+∞} x(u)du = \\sum_{-∞}^{+∞} x(u-v)du$ 를 구하는 것과 마찬가지로 적분을 임의의 그룹 요소로 \"시프트\"하여 동일한 결과를 얻을 수 있습니다.\n",
    "\n",
    "유클라디안 도매인 $Ω = \\mathbb{R}$인 경우를 고려해 봅시다. 컨볼루션을 패턴 매칭 연산으로 이해할 수 있습니다. 필터 $\\theta(u)$의 시프트 복사본을 입력 신호 $x(u)$와 매칭하는 것입니다. 한 점 $u$에서 컨볼루션$(x \\star \\theta)(u)$의 값은 신호 $x$와 필터가 $u$만큼 시프트된 신호의 내적 곱입니다,\n",
    "\n",
    "$$\n",
    "(x \\star \\theta)(u) = \\langle x, S_u \\theta \\rangle = \\int_\\mathbb{R} x(v)\\theta(u + v)dv.\n",
    "$$\n",
    ".\n",
    "\n",
    ">여기서 정의하는 것은 컨볼루션이 아니라 '컨볼루션'이라는 이름으로 딥 러닝에서 암묵적으로 사용되는 교차 상관관계(cross-correlation)입니다. 다음 논의와의 일관성을 위해 $(ρ(\\mathfrak{g})x)(u) = x(u - v), (ρ(\\mathfrak{g}^{-1})x)(u) = x(u + v)$로 표기합니다.\n",
    "\n",
    "이 경우 $u$는 도메인 $Ω = \\mathbb{R}$의 한 점인 동시에 변환 그룹의 원소이며, 도메인 자체로 식별할 수 있는 $\\mathfrak{G} = \\mathbb{R}$입니다. 이제 변환 그룹을 $Ω$에 작용하는 다른 그룹 $\\mathfrak{G}$로 간단히 대체하여 이 구조를 일반화하는 방법을 보여드리겠습니다.\n",
    "\n",
    "### 그룹 컨볼루션\n",
    "Group convolution\n",
    "\n",
    "섹션 3에서 설명한 것처럼, 영역 Ω에 대한 그룹 $\\mathfrak{G}$의 작용은 $ρ(\\mathfrak{g})x(u) = x(\\mathfrak{g}^{-1} u)$ 를 통해 신호 $\\mathcal{X} (Ω)$ 공간에 대한 $\\mathfrak{G}$의 표현 $ρ$를 유도합니다. 위의 예에서 $\\mathfrak{G}$는 좌표 $(u + v)$ 를 이동시켜 작용하는 요소를 가진 변환 그룹이며, $ρ(\\mathfrak{g})$는 신호에 $(S_vx)(u) = x(u - v)$로 작용하는 시프트 연산자입니다. 마지막으로 신호에 필터를 적용하기 위해 $\\mathcal{X} (Ω)$가 힐버트 공간이고 내적 곱이 있다는 가정을 호출합니다.\n",
    "\n",
    "$$\n",
    "\\langle x, θ \\rangle = \\int_{Ω} x(u)\\theta(u)du,\n",
    "$$\n",
    "\n",
    "여기서 단순화를 위해 스칼라 값 신호인 $\\mathcal{X} (Ω, \\mathbb{R})$를 가정했으며, 일반적으로 내적은 방정식 (2)의 형태를 갖습니다.\n",
    "\n",
    ">적분은 $Ω$에 대한 불변 측정값 $µ$에 대해 수행됩니다. $µ$가 불연속적인 경우, 이는 $Ω$에 대한 합계를 의미합니다. w.r.t = with respect to\n",
    "\n",
    "이렇게 신호를 변환하고 필터와 일치시키는 방법을 정의했으면,이제 $Ω$의 신호에 대한 그룹 컨볼루션( group convolution)을 정의할 수 있습니다,\n",
    "\n",
    "$$\n",
    "(x \\star \\theta)(\\mathfrak{g}) = \\langle x, ρ(\\mathfrak{g})\\theta \\rangle  = \\int_{Ω} x(u)\\theta(\\mathfrak{g}^{-1}u)du. \\tag{14}\n",
    "$$\n",
    "\n",
    "$x \\star \\theta$는 도메인 $Ω$의 점이 아닌 그룹 $\\mathfrak{G}$의 요소 $\\mathfrak{g}$에 대한 값을 취합니다. 따라서 $x \\star \\theta$를 입력으로 받는 다음 레이어는 그룹 $\\mathfrak{G}$에 정의된 신호에 대해 작동해야 하며, 이는 곧 다시 설명하겠습니다.\n",
    "\n",
    "전통적인 유클리드 컨볼루션이 시프트 등변수(shift-equivariant)인 것과 마찬가지로, 보다 일반적인 그룹 컨볼루션은 $\\mathfrak{G}$ 등변수($\\mathfrak{G}$-equivariant)입니다. 여기서 중요한 점은 신호 $x$ 를 $\\mathfrak{g}$-변환된($\\mathfrak{g}$-transformed) 필터 $ρ(\\mathfrak{g})θ$와 일치시키는 것은 역변환된 신호 $ρ(\\mathfrak{g}^{-1})x$를 변환되지 않은 필터 $θ$와 일치시키는 것과 동일하다는 것입니다. 수학적으로 이는 $\\langle x, ρ(\\mathfrak{g})θ \\rangle = \\langle ρ(\\mathfrak{g}^{-1})x, θ\\rangle$로 표현할 수 있습니다. 이러한 통찰력을 통해 그룹 컨볼루션(14)의 $\\mathfrak{G}$-등분은 그 정의와 그룹 표현의 정의 속성 $ρ(\\mathfrak{h}^{-1})ρ(\\mathfrak{g}) = ρ(\\mathfrak{h}^{-1}\\mathfrak{g})$로부터 바로 이어집니다,\n",
    "\n",
    "$$\n",
    "    (ρ(\\mathfrak{h})x \\star θ)(\\mathfrak{g})\n",
    "    = \\langle ρ(\\mathfrak{h})x, ρ(\\mathfrak{g})θ \\rangle \n",
    "    = \\langle x, ρ(\\mathfrak{h}^{-1} \\mathfrak{g})θ \\rangle\n",
    "    = ρ(\\mathfrak{h})(x \\star θ)(\\mathfrak{g}). \n",
    "$$\n",
    "\n",
    "몇 가지 예를 살펴봅시다. 위에서 공부한 1차원 격자의 경우는 $Ω = \\mathbb{Z}_n = \\{0, ... . , n - 1\\}$과 주기적 시프트(cyclic shift) 그룹 $\\mathfrak{G} = \\mathbb{Z}_n$을 선택하면 얻을 수 있습니다. 이 경우 그룹 요소는 인덱스의 순환 이동으로, 즉 $\\mathfrak{g} ∈ \\mathfrak{G}$ 요소는 일부 $u = 0, . . . , n - 1$로  $\\mathfrak{g}.v = v - u \\text{ mod }n$ 식별할 수 있으며, 그 반대의 요소는 $\\mathfrak{g}^{-1}.v = v + u \\text{ mod }n$입니다. 중요한 것은 이 예에서 그룹의 요소(시프트)는 영역의 요소(인덱스)이기도 하다는 점입니다. 따라서 표기법을 약간 남용하여 두 구조를 식별할 수 있습니다(즉, $Ω = \\mathfrak{G}$). 이 경우 그룹 컨볼루션에 대한 표현은 다음과 같습니다. \n",
    "\n",
    "$$\n",
    "    (x \\star θ)(\\mathfrak{g}) = \\sum^{n-1}_{v=0} x_v θ_{\\mathfrak{g}^{-1}v} ,\n",
    "$$\n",
    "\n",
    "는 익숙한 컨볼루션 $(x \\star θ)_u = \\sum^{n-1}_{v=0} x_v θ_{ v + u \\text{ mod }n}$ 으로 이어집니다.\n",
    "\n",
    ">사실 여기에서도 이것은 교차 상관 관계입니다. \n",
    "\n",
    "### 구형 컨볼루션\n",
    "Spherical convolution\n",
    "\n",
    "이제 회전 그룹인 특수 직교 그룹(special orthogonal group) $\\mathfrak{G} = SO(3)$가 있는 2차원 구체 $Ω = \\mathbb{S}^2$를 생각해 보겠습니다. 이 예는 교육적인 이유로 선택되었지만 실제로는 매우 실용적이며 수많은 응용 분야에서 발생합니다. 예를 들어 천체 물리학에서 관측 데이터는 자연적으로 구형 기하학적 구조를 갖는 경우가 많습니다. 또한 화학에서 분자를 모델링하고 그 특성을 예측할 때(예: 가상 약물 스크리닝 목적) 구형 대칭은 매우 중요합니다.\n",
    "\n",
    ">플랑크 우주 관측소에서 포착한 우주 마이크로파 배경 복사는 $\\mathbb{S}^2$ 의 신호입니다.\n",
    "\n",
    "구체의 한 점을 3차원 단위 벡터 $u : \\|u\\| = 1$로 표현하면, 그룹의 동작은 $det(\\mathbf{R}) = 1$의 $3 × 3$ 직교 행렬 $\\mathbf{R}$로 나타낼 수 있습니다. 따라서 구형 컨볼루션은 신호와 회전 필터 사이의 내적 곱으로 작성할 수 있습니다,\n",
    "\n",
    "$$\n",
    "\t(x \\star θ)(\\mathbf{R}) = \\int_{\\mathbb{S}^2} x(\\mathbf{u})θ(\\mathbf{R}^{-1}\\mathbf{u})d\\mathbf{u}. \n",
    "$$\n",
    "\n",
    "가장 먼저 주목해야 할 점은 그룹이 영역과 동일하지 않다는 점입니다. 그룹 $SO(3)$은 라이(Lie) 그룹으로 실제로는 3차원 다양체이지만, $\\mathbb{S}^2$는 2차원 다양체입니다. 따라서 이 경우에는 이전 예와 달리 컨볼루션은 $Ω$이 아닌 $SO(3)$에 대한 함수입니다.\n",
    "\n",
    "기하학적 딥러닝 블루프린트에서는 이전 연산자의 출력에 후속 연산자를 적용하여 여러 개의 등변량(equivariant) 지도(딥러닝 전문 용어로 '레이어')를 연결합니다. 번역(translations)의 경우 출력이 모두 동일한 도메인 Ω에 정의되어 있으므로 여러 컨볼루션을 순차적으로 적용할 수 있습니다. 일반적인 환경에서 $x \\star θ$는 $Ω$이 아닌 $\\mathfrak{G}$에 대한 함수이기 때문에 정확히 동일한 연산을 연속적으로 사용할 수 없습니다. 즉, 다음 연산은 $\\mathfrak{G}$의 신호, 즉 $x ∈ \\mathcal{X} (\\mathfrak{G})$를 처리해야 합니다. 그룹 컨볼루션의 정의는 이러한 경우를 허용합니다. $\\mathfrak{G}$의 구성 연산에 의해 정의된 그룹 작용 $(\\mathfrak{g, h}) \\mapsto \\mathfrak{gh}$를 통해 $\\mathfrak{G}$ 자체에 의해 작용하는 영역 $Ω = \\mathfrak{G}$로 간주하면 $(ρ(\\mathfrak{g})x)(\\mathfrak{h}) = x(\\mathfrak{g}^{-1}\\mathfrak{h})$로 $x ∈ \\mathcal{X} (\\mathfrak{G})$에 작용하는 $ρ(\\mathfrak{g})$ 표현이 산출됩니다. 이전과 마찬가지로 내부 곱은 신호와 필터의 점 단위(point-wise) 곱을 도메인에 적분하여 정의되며, 이제 $Ω = G$와 같습니다. 구형 컨볼루션의 예에서 두 번째 컨볼루션 계층은 다음과 같은 형식을 갖습니다.\n",
    "\n",
    "$$\n",
    "    ((x \\star θ) \\star φ)(\\mathbf{R}) = \\int_{SO(3)} (x \\star θ)(\\mathbf{Q})φ(\\mathbf{R}^{-1}\\mathbf{Q})d\\mathbf{Q}.\n",
    "$$\n",
    ".\n",
    "\n",
    ">$\\mathbb{S}^2$ 에 대한 $SO(3)$ 그룹의 작용입니다. $SO(3)$은 3차원 다양체이므로 세 가지 유형의 회전이 가능합니다.\n",
    "\n",
    ">G 자체에 정의된 함수에 작용하는 $\\mathfrak{G}$의 표현을 $\\mathfrak{G}$의 정규 표현이라고 합니다. \n",
    "\n",
    "컨볼루션에는 도메인 Ω에 대한 적분이 필요한 내적분이 포함되므로, 도메인 $Ω$이 작거나(이산형의 경우) 저차원(연속형의 경우)인 경우에만 컨볼루션을 사용할 수 있습니다. 예를 들어 평면 $\\mathbb{R}^2$(2차원) 또는 특수 직교 그룹 $SE(3)$(3차원) 또는 그래프의 유한 노드 집합(n차원)에서는 컨볼루션을 사용할 수 있지만, 실제로는 $n!$ 요소가 있는 순열 그룹 $Σ_n$에서는 컨볼루션을 수행할 수 없습니다. 마찬가지로 아핀 그룹과 같은 고차원 그룹(이동, 회전, 전단, 스케일링 등 총 6차원 포함)에 대한 적분도 실제로는 불가능합니다. 그럼에도 불구하고 5.3절에서 살펴본 것처럼 $\\mathfrak{G}$ 가 작용하는 저차원 공간 $Ω$에 정의된 신호로 작업하여 큰 그룹 $\\mathfrak{G}$에 대한 등변량 컨볼루션을 구축할 수 있습니다. 실제로 두 영역 $Ω, Ω'$ 사이의 모든 등변량 선형 맵 $f : \\mathcal{X} (Ω) →  \\mathcal{X} (Ω')$는 여기서 논의한 그룹 컨볼루션과 유사한 일반화된 컨볼루션으로 작성할 수 있음을 보여줄 수 있습니다.\n",
    "\n",
    "둘째, 이전 섹션에서 컨볼루션의 시프트-등분(shift-equivariance) 특성으로부터 도출한 푸리에 변환은 신호를 대칭 그룹의 환원 불가능한 표현의 행렬 요소에 투영함으로써 보다 일반적인 경우로 확장할 수 있다는 점에 주목합니다. 이에 대해서는 향후 작업에서 논의하겠습니다. 여기서 연구한 $SO(3)$의 경우, 이는 양자역학 및 화학에서 광범위하게 응용되는 구형 고조파(spherical harmonics)와 비그너 D-함수(Wigner D-functions)를 생성합니다. \n",
    "\n",
    "마지막으로, 지금까지 이 섹션의 논의를 뒷받침해 온 가정을 언급합니다. $Ω$이 격자, 평면 또는 구이든 상관없이 모든 점을 다른 점으로 변환할 수 있으며, 이는 직관적으로 도메인의 모든 점이 \"동일하게 보인다\"는 것을 의미합니다. 이러한 속성을 가진 영역 $Ω$을 동질 공간(homogeneous space)이라고 하며, 여기서 모든 $u, v ∈ Ω$에 대해 $\\mathfrak{g}.u = v$가 되는 $\\mathfrak{g ∈ G}$가 존재합니다. 다음 섹션에서는 이 가정을 완화해 보겠습니다.\n",
    "\n",
    ">여기서는 추가 속성인 $\\mathfrak{e}.u = u$ 및 $\\mathfrak{G}(\\mathfrak{h}.u) = (\\mathfrak{gh}).u$가 암묵적으로 가정됩니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ebf43ea",
   "metadata": {},
   "source": [
    "## 4.4 측지 및 매니폴드\n",
    "Geodesics and Manifolds\n",
    "\n",
    "지난 예제에서 구 $\\mathbb{R}^2$는 균질한 구조로 인해 전역 대칭 그룹을 가진 특수한 다양체였습니다. 안타깝게도 대부분의 다양체는 그렇지 않으며, 일반적으로 전역 대칭을 갖지 않습니다. 이 경우 $Ω$의 신호 공간에 대한 $\\mathfrak{G}$의 작용을 직접적으로 정의할 수 없으며, 이를 사용하여 필터를 '슬라이드'하여 컨볼루션을 고전적 구조의 직접 일반화로 정의할 수 없습니다. 그럼에도 불구하고 다양체에는 이 섹션에서 살펴볼 두 가지 유형의 불변성(invariance), 즉 미터법 구조(metric structure)를 보존하는 변환과 국소 기준 프레임 변경(local reference frame change)이 있습니다.\n",
    "\n",
    ">회전 그룹 $SO(3)$도 라이(Lie) 그룹이기 때문에 마찬가지입니다.\n",
    "\n",
    "많은 머신 러닝 독자에게 다양체는 다소 생소한 개념으로 보일 수 있지만, 사실 다양한 과학 영역에서 매우 흔한 개념입니다. 아인슈타인의 일반 상대성 이론에 따르면 중력은 유사 리만 다양체로 모델링된 시공간 곡률에서 발생하며, 물리학에서 다양체는 우리 우주의 모델로서 중심적인 역할을 합니다. 컴퓨터 그래픽이나 시각과 같은 보다 '산문적인(prosaic)' 분야에서 다양체는 3D 도형의 일반적인 수학적 모델입니다. 이러한 모델의 광범위한 응용 분야는 가상 및 증강 현실과 '모션 캡처'를 통해 얻은 특수 효과부터 3D 퍼즐 조각처럼 서로 달라붙는(화학 전문 용어로 '결합') 단백질 상호작용을 다루는 구조 생물학에 이르기까지 다양합니다. 이러한 응용 분야의 공통 분모는 3D 물체의 경계면을 표현하기 위해 매니폴드를 사용한다는 점입니다.\n",
    "\t\n",
    ">'3D'라는 용어는 다소 오해의 소지가 있으며 임베딩(embedding) 공간을 의미합니다. 도형 자체는 2D 다양체(서피스 (surfaces))입니다.\n",
    "\n",
    "이러한 모델이 편리한 데에는 몇 가지 이유가 있습니다. 첫째, 3D 오브젝트에 대한 간결한 설명을 제공하므로 그리드 기반 표현에서 필요한 '빈 공간'에 메모리를 할당할 필요가 없습니다. 둘째, 객체의 내부 구조를 무시할 수 있습니다. 이는 예를 들어 단백질 분자의 내부 접힘이 분자 표면에서 일어나는 상호 작용과 무관한 경우가 많은 구조 생물학에서 유용한 속성입니다. 셋째, 가장 중요한 것은 비강성(non-rigid)변형을 겪는 변형 가능한(deformable) 물체를 다루어야 하는 경우가 많다는 점입니다. 앞서 언급한 모션 캡처 및 가상 아바타와 같은 컴퓨터 그래픽스 및 시각 분야의 많은 애플리케이션은 변형 불변성(deformation invariance)을 필요로 합니다. 이러한 변형은 (리만) 다양체의 고유 구조, 즉 다양체가 주변 공간에 포함되는 방식에 관계없이 다양체를 따라 측정된 점 사이의 거리를 보존하는 변형으로 매우 잘 모델링할 수 있습니다. \n",
    "\n",
    ">인체는 거의 등각 투영(nearly-isometric) 방식으로 변형되는 비강체 물체의 예입니다.\n",
    "\n",
    "기하학적 딥 러닝 청사진에서 다양체는 다양한 영역의 설정에 속하며, 이런 의미에서 그래프와 유사하다는 점을 강조하고 싶습니다. 3.3절에서 '기하학적 안정성'이라고 부르는 도메인 변형에 대한 불변성 개념의 중요성을 강조하겠습니다. 미분 기하학은 머신 러닝 청중에게 익숙하지 않을 수 있으므로, 여기서는 논의에 필요한 기본 개념만 소개하고 자세한 설명은 Penrose(2005)를 참고하시기 바랍니다.\n",
    "\n",
    "### 리만 다양체\n",
    "Riemannian manifolds\n",
    "\n",
    "다양체의 공식적인 정의는 다소 복잡하기 때문에, 정확도를 약간 희생하는 대신 직관적인 그림을 제공하는 것을 선호합니다. 이러한 맥락에서 (미분 또는 평활(differentiable or smooth)) 다양체를 국부적으로 유클리드인 부드러운 다차원 곡면으로 생각할 수 있는데, 어떤 점 주변의 작은 이웃은 $\\mathbb{R}^s$의 이웃으로 변형될 수 있다는 의미에서 이 경우 다양체는 S 차원이라고 합니다. 이를 통해, 탄젠트 공간(tangent space) $T_uΩ$을 통해 점 $u$ 주변의 다양체를 국부적으로 근사화할 수 있습니다. 후자는 전형적인 2차원 다양체, 구,를 생각하고 한 점에 평면을 붙이는 것으로 시각화할 수 있습니다. 충분한 확대/축소를 사용하면 구면이 평면처럼 보일 것입니다(그림 11). 모든 탄젠트 공간의 집합을 탄젠트 번들(tangent bundle)($TΩ$)이라고 하며, 번들의 개념은 4.5절에서 더 자세히 설명하겠습니다. \n",
    "\n",
    ">여기서 '매끄럽다'는 것은 편의상 암묵적으로 가정하는 미분 가능한 충분한 횟수를 의미합니다. 여기서 '변형'이란 이형(diffeomorphic), 즉 매끄러운 반전 맵을 사용하여 두 이웃 사이를 매끄러운 반전 맵으로 매핑할 수 있다는 의미입니다.\n",
    "\n",
    ">공식적으로 탄젠트 번들은 불연속 합집합(disjoint union) $TΩ = \\coprod_{u∈Ω} T_uΩ$입니다.\n",
    "\n",
    "$X ∈ T_uΩ$으로 표시되는 탄젠트 벡터(tangent vector)는 점 u로부터의 국소 변위로 생각할 수 있습니다. 탄젠트 벡터의 *길이*와 그 사이의 *각도*를 측정하려면 탄젠트 공간에 양정확한 2선 함수(positive-definite bilinear function) $g_u : T_uΩ×T_uΩ → \\mathbb{R}$로 표현되는 추가 구조를 갖추어야 하며, 이는 $u$에 부드럽게 의존합니다. 이러한 함수는 1856년 이 개념을 도입한 베른하르트 리만의 이름을 따서 리만 메트릭(Riemannian metric)이라고 하며, 두 접선 벡터 $X, Y ∈ T_uΩ$ 사이의 각도를 표현하는 접선 공간의 내적 곱인 $\\langle X, Y \\rangle_u = g_u(X, Y )$로 생각할 수 있습니다. 이 메트릭은 또한 벡터의 길이를 국부적으로 측정할 수 있는 $\\| X\\|_u = g_u^{1/2}(X, X)$라는 규범(norm)을 유도합니다.\n",
    "\n",
    ">0이 아닌 벡터 $X \\neq 0$에 대해 $g(X, X)> 0$이면 이선(bilinear) 함수 $g$는 양의 정의( positive-definite) 함수라고 합니다. $g$가 행렬 $G$로 표현되면 $G \\succ 0$을 의미합니다. 행렬식 $|G|^{1/2}$은 기저의 선택(the choice of the basis)에 의존하지 않는 국부적 체적 요소(local volume element)를 제공합니다.\n",
    "\n",
    "탄젠트 벡터는 그 자체로 존재하며 좌표가 없는(coordinate-free) 추상적인 기하학적 실체라는 점을 강조해야 합니다. 탄젠트 벡터 $X$를 숫자의 배열로 수치로 표현하려면 일부 국부 기저 $\\{X_1, . . . . . X_s\\} ⊆ T_uΩ$에 연관된 좌표들 $x = (x_1, . . . , x_s)$의 리스트로만 표현할 수 있습니다.마찬가지로 메트릭은 해당 기저에서 원소 $g_{ij} = g_u(X_i , X_j)$를 갖는 $s × s$ 행렬 $\\mathbf{G}$로 표현할 수 있습니다. 이 부분은 4.5절에서 다시 다루겠습니다.\n",
    "\n",
    ">안타깝게도 벡터를 좌표로 식별하는 경우가 너무 많습니다. 이 중요한 차이점을 강조하기 위해 탄젠트 벡터를 나타내는 데는 $X$를, 좌표를 나타내는 데는 $x$를 사용합니다.\n",
    "\n",
    "메트릭을 가진 다양체를 리만 다양체(Riemannian manifold)라고 하며, 전적으로 메트릭으로 표현할 수 있는 성질을 내재적(intrinsic) 성질이라고 합니다. 템플릿에 따르면, 우리는 $Ω$에 정의된 신호에 작용하는 함수를 구축하려고 하는데, 이 함수는 국부 구조(local structure)에 영향을 주지 않고 다양체를 변형하는 아이소메트리(isometries)라고 하는 메트릭 보존(metric-preserving) 변환에 불변(invariant)하기 때문에 논의에서 중요한 개념입니다. 이러한 함수를 내재량(intrinsic quantities)으로 표현할 수 있다면 자동으로 아이소메트리 불변성(isometry-invariant)이 보장되므로 아이소메트리 변형에 영향을 받지 않습니다. 이러한 결과는 근사 아이소메트리를 처리하는 것으로 더 확장할 수 있으며, 이는 청사진에서 논의한 기하학적 안정성(도메인 변형)의 한 예입니다. \n",
    "\n",
    "앞서 언급했듯이 리만 다양체의 정의는 어떤 공간에서도 기하학적 구현을 필요로 하지 않지만, 유클리드 공간의 구조를 사용해 리만 메트릭을 유도하면, 모든 매끄러운(smooth) 리만 다양체를 충분히 높은 차원의 유클리드 공간의 하위 집합으로 구현할 수 있습니다(이 경우 해당 공간에 '내장'되어 있다고 함). 그러나 이러한 임베딩이 반드시 고유(unique)한 것은 아닙니다. 앞으로 살펴보겠지만, 리만 메트릭의 두 가지 다른 아이소메트릭 구현이 가능합니다.\n",
    "\n",
    ">이 결과는 내쉬(1956)에 의해 임베딩 정리(Embedding Theorem)로 알려져 있습니다. 종이접기 기술은 $\\mathbb{R}^3$에서 평면 표면의 다양한 아이소메트릭 임베딩을 표현한 것입니다(그림: Shutterstock/300 librarians).\n",
    "\n",
    "### 스칼라 및 벡터 필드\n",
    "Scalar and Vector fields\n",
    "\n",
    "우리는 $Ω$에 정의된 신호에 관심이 있으므로, 다양체에서 스칼라 및 벡터 값 함수에 대한 적절한 개념을 제공해야 합니다. (평활 (smooth)) 스칼라 필드(scalar field)는 $x : Ω → \\mathbb{R}$ 형식의 함수입니다. 스칼라 필드는 내부 곱(inner product)을 갖출 수 있는 벡터 공간 $\\mathcal{X}(Ω, \\mathbb{R})$를 형성합니다.\n",
    "\n",
    "$$\n",
    "    \\langle x, y \\rangle = \\int_Ω x(u)y(u)du, \\tag{15}\n",
    "$$\n",
    "\n",
    "여기서 $du$는 리만 메트릭에 의해 유도된 체적 요소(volume element)입니다. (평활한 (smooth)) 탄젠트 벡터장(tangent vector field)은 각 점에 각 탄젠트 공간의 탄젠트 벡터를 할당하는 $X : Ω → TΩ$ 형식의 함수입니다($u \\mapsto X(u) ∈ T_uΩ$). 벡터장(Vector fields)은 또한 리만 메트릭을 통해 정의된 내적 곱을 가진 벡터 공간 $\\mathcal{X}(Ω, TΩ)$를 형성합니다,\n",
    "\n",
    "$$\n",
    "    \\langle X, Y \\rangle = \\int_Ω g_u(X(u), Y(u))du. \\tag{16}\n",
    "$$\n",
    "\n",
    "### 내재적 그라데이션\n",
    "Intrinsic gradient\n",
    "\n",
    "벡터 필드를 생각하고 (실제로 정의하는) 또 다른 방법은 미분이라는 일반화된 개념입니다. 고전 미적분학에서는 미분(differential) $dx(u) = x(u + du) - x(u)$를 통해 (매끄러운) 함수를 국부적으로 선형화할 수 있는데, 이는 무한히 작은 변위 du의 결과로서 점 u에서 함수 x의 값의 변화를 제공합니다. 그러나 우리의 경우에는 전역 벡터 공간 구조가 없기 때문에, 다양체에서 \"$u + du$\" 형식의 식은 의미가 없고 이로 인해 이 정의를 순진하게 사용하는 것은 불가능합니다. \n",
    "\n",
    "해결책은 탄젠트 벡터를 국소 무한 변위(local infinitesimal displacement)의 모델로 사용하는 것입니다. 매끄러운 스칼라 필드 $x ∈ \\mathcal{X} (Ω, \\mathbb{R})$가 주어지면, (매끄러운) 벡터 필드는 미분의 특성을 만족하는 선형 맵 $Y : \\mathcal{X} (Ω, \\mathbb{R}) → \\mathcal{X} (Ω, \\mathbb{R})$로 생각할 수 있습니다: 모든 상수 $c$에 대해 $Y(c) = 0$(상수 함수는 소실 도함수(vanishing derivatives)를 갖는다는 직관에 해당), 모든 평활 스칼라 필드 $x, z ∈ \\mathcal{X} (Ω, \\mathbb{R})$에 대해 $Y(x + z) = Y(x) + Y(z)$(선형성), 그리고 $Y(xz) = Y(x)z + xY(z)$(곱 또는 라이프니츠 법칙(Leibniz rule))입니다. 이러한 특성을 사용하여 벡터 필드를 공리적으로 정의할 수 있음을 보여줄 수 있습니다. 미분 $dx(Y ) = Y(x)$는 연산자 $(u, Y ) \\mapsto Y(x)$로 볼 수 있으며 다음과 같이 해석할 수 있습니다: 점 $u$에서 변위 $Y ∈ T_uΩ$의 결과로서 $x$의 변화는 $d_ux(Y)$로 주어집니다. 따라서 방향 미분(directional derivative)이라는 고전적인 개념이 확장된 것입니다.\n",
    "\n",
    ">중요한 것은 이 구조는 리만 메트릭을 전혀 사용하지 않으므로, 4.5절에서 설명한 보다 일반적인 번들 구조로 확장할 수 있다는 점입니다.\n",
    "\n",
    "또는 각 점 $u$에서 미분은 접선 벡터 $X ∈ T_uΩ$에 작용하는 선형 함수 (linear functional) $dx_u : T_uΩ → \\mathbb{R}$로 간주할 수 있습니다. 벡터 공간의 선형 함수를 이중 벡터(dual vectors) 또는 코벡터(covectors)라고 하며, 여기에 내적 곱(리만 메트릭)이 주어지면 이중 벡터는 항상 다음과 같이 나타낼 수 있습니다.\n",
    "\n",
    "$$\n",
    "    dx_u(X) = g_u(∇x(u), X)\n",
    "$$\n",
    ".\n",
    "\n",
    ">이는 모든 이중 벡터를 벡터의 내적 곱으로 표현할 수 있는 리즈-프레셰 표현 정리(Riesz-Fréchet Representation Theorem)의 결과입니다.\n",
    "\n",
    "점 u에서의 미분의 표현은 x의 (내재 (intrinsic)) 기울기라고 하는 접선 벡터 ∇x(u) ∈ TuΩ이며, 고전 미적분학의 기울기와 유사하게 x가 가장 가파르게 증가하는 방향으로 생각할 수 있습니다. 연산자 ∇ : X (Ω, R) → X (Ω, TΩ)로 간주되는 기울기는 각 점에 x(u) 7→ ∇x(u) ∈ TuΩ을 할당하므로, 스칼라 필드 x의 기울기는 벡터 필드 ∇x입니다.\n",
    "\n",
    "### 측지학\n",
    "Geodesics\n",
    "\n",
    "이제 끝점이 $u = γ(0), v = γ(T)$인 다양체 위의 매끄러운 곡선 $γ : [0, T] → Ω$을 생각해 봅시다. 점 t에서 곡선의 미분은 속도 벡터(velocity vector)라고 하는 접선 벡터(tangent vector) $γ' (t) ∈ T_{γ(t)}Ω$입니다. 점 u와 v를 연결하는 모든 곡선 중에서 길이가 최소인 곡선, 즉 길이 함수를 최소화하는 γ를 구하는 데 관심이 있습니다. \n",
    "\n",
    "$$\n",
    "    \\ell(γ) = \\int^{T}_{0} \\|γ'(t)\\|_{γ^{(t)}}dt\n",
    "             = \\int^{T}_{0} g_{γ^{(t)}}^{1/2}(γ'(t), γ'(t))dt.\n",
    "$$\n",
    ".\n",
    "\n",
    ">커브는 호 길이 매개변수화(arclength parametrisation)로 주어지므로 $\\|γ'\\| = 1$(등속)이라고 암묵적으로 가정합니다.\n",
    "\n",
    "이러한 곡선을 측지(geodesics)(그리스어 γεοδαισία, 문자 그대로 '지구의 분할'에서 유래)라고 하며, 미분 기하학에서 중요한 역할을 합니다. 이 논의에서 결정적으로 중요한 것은, 측지법을 정의하는 방식이 리만 측정법(길이 함수를 통한)에만 의존한다는 점입니다.\n",
    "\n",
    "미분 기하학에 익숙한 독자라면 측지학이 더 일반적인 개념이며, 실제로 측지학의 정의에는 리만 메트릭이 필요하지 않고, 우리의 미분 구조와 유사하게, 공리적으로 정의되는 연결(공변량 미분(covariant derivative)이라고도 하며, 미분의 개념을 벡터 및 텐서 필드에 일반화함)이 필요하다는 점을 기억하실 것입니다. 리만 측정값이 주어지면 리만 기하학에서 종종 암묵적으로 가정되는 리비-시비타(Levi-Civita) 연결이라는 고유한 특수 연결이 존재합니다. 이 연결에서 발생하는 측지법은 위에서 정의한 길이를 최소화하는 곡선입니다. \n",
    "\n",
    ">레비-시비타(Levi-Civita) 연결은 비틀림이 없고(torsion-free) 미터법과 호환됩니다(compatible with the metric). 리만 기하학의 기본 정리는 이 연결의 존재와 고유성을 보장합니다.\n",
    "\n",
    "다음에서는 측지법을 사용하여 다양체에서 접선 벡터를 전송하는 방법을 정의하고(병렬 전송(parallel transport)), 다양체에서 접선 공간(e tangent space)으로 로컬 고유 맵을 만들고(지수 맵(exponential map)), 거리를 정의하는(측지 메트릭(geodesic metric)) 방법을 보여드리겠습니다. 이를 통해 탄젠트 공간에 필터를 로컬로 적용하여 컨볼루션과 유사한 연산을 구성할 수 있습니다.\n",
    "\n",
    "### 병렬 전송\n",
    "parallel transport\n",
    "\n",
    "다양체를 다룰 때 이미 직면한 문제 중 하나는 두 점 $u, v ∈ Ω$을 직접 더하거나 뺄 수 없다는 것입니다. 서로 다른 지점에서 접하는 벡터를 비교하려고 할 때도 같은 문제가 발생하는데, 차원은 같지만 서로 다른 공간(예: $X ∈ T_uΩ$과 $Y ∈ T_vΩ$)에 속하기 때문에 직접 비교할 수 없습니다. 측지법(Geodesics)은 다음과 같은 방식으로 벡터를 한 점에서 다른 점으로 이동하는 메커니즘을 제공합니다. $γ$를 점 $u = γ(0), v = γ(T)$를 연결하는 측지법이라고 하고 $X ∈ T_uΩ$이라고 합니다. 측지선을 따라 새로운 접선 벡터(tangent vectors) 집합을 정의할 수 있는데, $X(t) ∈ T_{γ^(t)}Ω$으로 $X(t)$의 길이와 곡선의 속도 벡터 사이의 각도(리만 메트릭으로 표현)가 일정하도록 합니다,\n",
    "\n",
    "$$\n",
    "    g_{γ^{(t)}}(X(t), γ'(t)) = g_u(X, γ'(0)) = const, \\quad \\| X(t) \\|_{γ^{(t)}} = \\| X \\|_u = const.\n",
    "$$\n",
    "\n",
    "그 결과, 끝점 $v$에서 고유 벡터 $X(T) ∈ T_vΩ$을 얻습니다.\n",
    "\n",
    ">결과 벡터(빨간색)가 접하는 평면(tangent plane)에 있지 않기 때문에 A에서 C로 벡터의 유클리드 이동(Euclidean transport)은 구에서 의미가 없습니다. A에서 C로 평행 이동(Parallel transport)(파란색)은 경로를 따라 벡터를 회전시킵니다. 경로에 따라 달라집니다. 경로 BC와 ABC를 따라 이동하면 다른 결과가 생성됩니다.\n",
    "\n",
    "맵 $Γ_{u→v}(X) : T_uΩ → T_uΩ$과 위의 표기법을 사용하여 $Γ_{u→v}(X) = X(T)$로 정의된 $T_vΩ$을 평행 이동(parallel transport) 또는 연결(connection)이라고 하며, 후자의 용어는 접하는 공간(tangent spaces) $T_uΩ$과 $T_vΩ$을 '연결'하는 메커니즘이라는 의미를 내포하고 있습니다. 각도와 길이 보존 조건으로 인해 평행 이동은 벡터의 회전에 불과하므로 특수 직교 그룹 $SO(s)$(접선 다발의 구조 그룹이라고 함)의 원소와 연관될 수 있으며, 이를 $\\mathfrak{g}_{u→v}$로 표시하고 4.5절에서 더 자세히 설명하겠습니다.\n",
    "\n",
    ">매니폴드(다양체, manifold)가 방향이 가능하다(orientable)고 가정하면, 그렇지 않으면 $O(s)$\n",
    "\n",
    "앞서 언급했듯이 연결은 리만 메트릭과 무관하게 공리적으로 정의할 수 있으며, 따라서 모든 매끄러운 곡선을 따라 평행하게 이동하는 추상적인 개념을 제공합니다. 그러나 이러한 이동의 결과는 이동 경로에 따라 달라집니다.\n",
    "\n",
    "### 지수 맵\n",
    "Exponential map\n",
    "\n",
    "한 점 $u$를 중심으로 국부적으로 주어진 방향 $X ∈ T_uΩ$, 즉 $γ(0) = u, γ'(0) = X$로 항상 고유한 측지점(geodesic)을 정의할 수 있습니다. $γX^{(t)}$가 $0 ≥ t$ 모든 $t$에 대해 정의되면(즉, 한 점 $u$에서 원하는 만큼 측지점을 촬영(shoot)할 수 있으면), 다양체는 측지적으로 완전(geodesically complete)하고, 지수 맵은 전체 접선 공간(tangent space)에 정의된다고 할 수 있습니다. 콤팩트 다양체는 측지적으로 완전하기 때문에 우리는 이 편리한 속성을 암묵적으로 가정할 수 있습니다.\n",
    "\n",
    "이 측지 정의에 따라 점과 방향이 제공되면 접하는 공간 $T_uΩ$에서 $Ω$까지의 (하위 집합인) 자연 매핑을 지수 맵(exponential map) $\\exp$ 라고 합니다: $B_r(0) ⊂ T_uΩ → Ω$으로 정의되며, 이는 측지선을 따라 $X$ 방향으로 한 단위 걸음, 즉 $\\exp_u(X) = γX(1)$을 취함으로써 정의됩니다. 지수 맵 $\\exp_u$는 $T_uΩ$에서 원점의 이웃 $B_r(0)$(공 또는 반지름 $r$)을 $u$의 이웃으로 변형하기 때문에 국소적 미분동형사상(diffeomorphism)입니다. 반대로 지수 맵을 접선 공간에 대한 다양체의 본질적 국소 변형('평탄화')으로 간주할 수도 있습니다. \n",
    "\n",
    ">측지 완전성이 반드시 exp가 전역 미분동형사상(diffeomorphism)임을 보장하는 것은 아닙니다. $\\exp_u(B_r(0) ⊆ T_uΩ)$가 미분동형적으로 매핑되는 $u$에 대한 가장 큰 반지름 $r$을 주입 반경(injectivity radius)이라고 합니다.\n",
    "\n",
    "### 측지 거리\n",
    "Geodesic distances\n",
    "\n",
    "호프-리노우( Hopf-Rinow) 정리로 알려진 결과에 따르면 측지적으로 완전한 다양체는 완전한 미터법 공간(complete metric spaces)이며, 어떤 한 쌍의 점 $u, v$ 사이의 거리(측지 거리 또는 미터법이라고 함)를 그 사이의 최단 경로의 길이로 구현할 수 있습니다.\n",
    "\n",
    "$$\n",
    "    d_g(u, v) = \\min_γ \\ell (γ) \\quad \\text{ s.t.} \\quad γ(0) = u, γ(T) = v,\n",
    "$$\n",
    "\n",
    "가 존재하는 경우(즉, 최소값에 도달한 경우).\n",
    "\n",
    ">따라서 호프-리노우 정리는 측지적(geodesic) 완전성과 메트릭(metric) 완전성 사이의 동등성(equivalence)을 확립하며, 후자는 모든 코시(Cauchy) 수열이 측지적 거리 메트릭에 수렴한다는 것을 의미합니다.\n",
    "\n",
    ">'미터법'이라는 용어는 두 가지 의미로 사용된다는 점에 유의하세요: 리만 미터법(Riemannian metric) $g$와 거리(distance) $d$. 혼동을 피하기 위해 여기서는 후자를 가리키는 '거리(distance)'라는 용어를 사용합니다. $d_g$라는 우리의 표기는 거리(distance)는 리만 미터법 $g$에 따라 달라지게 하지만, 측지선 길이(geodesic length) $L$의 정의가 있습니다.\n",
    "\n",
    "\n",
    "### 아이소메트리\n",
    "Isometries\n",
    "\n",
    "이제 우리의 다양체 $Ω$을 리만 측정법 $h$를 가진 다른 다양체 $\\tilde{Ω}$ 로 변형하는 경우를 생각해 보겠습니다. 이 변형은 다양체 사이에 $η : (Ω, g) → (\\tilde{Ω}, h)$의 미분동형사상(diffeomorphism)이라고 가정합니다. 그 미분 $dη : TΩ → T\\tilde{Ω}$는 각각의 접선 다발 사이의 맵을 정의하며(푸시포워드(pushforward)라고 함), 한 점 $u$에서 우리는 $dη_u : T_uΩ → T_{η(u)}\\tilde{Ω}$를 가지며, 이는 이전과 같이 해석됩니다: 접선 벡터 $X ∈ T_uΩ$에 의해 점 $u$에서 작은 변위를 만들면, 맵 $η$는 접선 벡터 $dη_u(X) ∈ T_{η(u)}\\tilde{Ω}$에 의해 점 $η(u)$에서 변위될 것입니다.\n",
    "\n",
    "푸시포워드가 두 다양체의 접선 벡터를 연결하는 메커니즘을 제공하기 때문에 메트릭 $h$를 $\\tilde{Ω}$에서 $Ω$으로 되돌릴(pullback) 수 있습니다,\n",
    "\n",
    "$$\n",
    "    (η^{∗}h)_u(X, Y ) = h_{η(u)}(dη_u(X), dη_u(Y))\n",
    "$$\n",
    "\n",
    "풀백(pullback) 메트릭이 모든 점에서 $Ω$의 메트릭과 일치하는 경우, 즉 $g = η^∗h$인 경우, 맵 $η$를 (리만) 아이소메트리(isometry)라고 부릅니다. 2차원 다양체(표면(surfaces))의 경우 아이소메트리는 다양체를 '늘리거나(stretching)' '찢지(tearing)' 않고 변형하는 비탄성(inelastic) 변형으로 직관적으로 이해할 수 있습니다.\n",
    "\n",
    ">푸시포워드(Pushforward)와 풀백(pullback)은 인접(adjoint) 연산자 $\\langle η^{\\ast}α, X\\rangle = \\langleα, η_{\\ast} X \\rangle$이며, 여기서 $α ∈ T^{\\ast}Ω$ 이중 벡터장(dual vector field)으로, 각 지점에서 $T_uΩ$에 작용하는 선형 함수로 정의되고 내적은 벡터장과 이중 벡터장에 각각 정의됩니다.\n",
    "\n",
    "아이소메트리는 그 정의에 따라 측지 거리(geodesic distances)와 같은 본질적인 구조를 보존하며, 이는 전적으로 리만 미터법으로 표현됩니다. 따라서, 미터법 기하학의 관점에서 아이소메트리를 미터법 공간 $η : (Ω, d_g) → (\\tilde{Ω}, d_h)$ 사이의 거리 보존 지도('미터법 아이소메트리(metric isometries)')로 이해할 수도 있습니다. 같은 관점으로, \n",
    "\n",
    "$$\n",
    "    d_g(u, v) = d_h(η(u), η(v)) \n",
    "$$\n",
    "\n",
    "모든 $u, v ∈ Ω$에 대해, 또는 더 간결하게는 $d_g = d_h ◦ (η × η)$입니다. 다시 말해, 리만 아이소메트리(Riemannian isometries)는 미터법 아이소메트리(metric isometries)이기도 합니다. 연결된(connected) 다양체에서는 그 반대의 경우도 마찬가지입니다. 모든 미터법 아이소메트리는 리만 아이소메트리이기도 합니다.\n",
    "\n",
    ">이 결과를 마이어스-스텐로드(Myers–Steenrod) 정리라고 합니다. 우리는 암묵적으로 다양체가 연결되어 있다고 가정합니다.\n",
    "\n",
    "기하학적 딥 러닝 블루프린트에서 $η$는 도메인 변형의 모델입니다. $η$가 아이소메트리인 경우, 모든 고유 수량(quantities)은 이러한 변형의 영향을 받지 않습니다. 미터법 확장 개념(the notions of metric dilation)을 통해 정확한 (미터법) 아이소메트리를 일반화할 수 있습니다.\n",
    "\n",
    "$$\n",
    "    dil(η) = \\sup_{u  \\ne v∈Ω} \\frac{d_h(η(u), η(v))}{d_g(u, v)}\n",
    "$$\n",
    "\n",
    "또는 메트릭 왜곡(metric distortion)\n",
    "\n",
    "$$\n",
    "    dis(η) = \\sup_{u,v∈Ω} | d_h(η(u), η(v)) − d_g(u, v) |\n",
    "$$\n",
    "\n",
    "는 각각 $η$ 하에서 측지 거리의 상대적 및 절대적 변화를 포착합니다. 도메인 변형에 따른 함수 $f ∈ \\mathcal{F(X} (Ω))$의 안정성에 대한 조건 (5)는 이 경우 다음과 같이 재작성할 수 있습니다.\n",
    "\n",
    "$$\n",
    "    \\|f(x, Ω) - f(x ◦ η^{-1} , \\tilde{Ω})  \\| ≤ C \\| x \\|dis(η).\n",
    "$$\n",
    ".\n",
    "\n",
    ">3.2절에서 언급한 미터법 공간 사이의 그로모프-하우스도르프(Gromov-Hausdorf) 거리는 가능한 가장 작은 미터법 왜곡으로 표현할 수 있습니다.\n",
    "\n",
    "### 내재적 대칭\n",
    "Intrinsic symmetries\n",
    "\n",
    "위의 특별한 경우는 도메인 자체의 미분동형사상(diffeomorphism)(3.2절에서 자동형성(automorphism)이라고 불렀던 것)으로, $τ ∈ \\text{Diff}(Ω)$로 표시할 것입니다. 풀백 메트릭이 $τ^∗ g = g$를 만족하면, 리만 (자기) 아이소메트리(a Riemannian (self-)isometry)라고 하고, 또는 $d_g = d_g◦(τ×τ)$를 만족하면, 메트릭 (자기) 아이소메트리(a metric (self-)isometry)라고 부릅니다. 당연하게도 동형사상(isometries)은 $\\text{Iso}(Ω)$로 표시되는 구성 연산자와 함께 그룹을 형성하고 동형 그룹(isometry group)이라고 불리며, 동일 원소는 맵 $τ(u) = u$이고 역은 항상 존재합니다($τ$를 미분동형사상(diffeomorphism)으로 정의하기 때문에). 따라서 자기 등각 투영(Self-isometries)은 다양체의 본질적인 대칭(intrinsic symmetries)입니다.\n",
    "\n",
    ">다양체의 연속 대칭은 빌헬름 킬링(Wilhelm Killing)의 이름을 딴 킬링 필드(Killing fields)라는 특수 접선 벡터장에 의해 무한히 생성됩니다.\n",
    "\n",
    "### 매니폴드에 대한 푸리에 분석\n",
    "Fourier analysis on Manifolds\n",
    "\n",
    "이제 구성상 등각 변형(isometric deformations)에 불변(invariant)인 다양체에서 내재 컨볼루션과 유사한 연산을 구성하는 방법을 보여드리겠습니다. 이를 위해 두 가지 옵션이 있습니다: 하나는 푸리에 변환의 유추를 사용하여 컨볼루션을 푸리에 영역의 곱으로 정의하는 것입니다. 다른 하나는 필터를 신호와 로컬로 연관시켜 컨볼루션을 공간적(spatially)으로 정의하는 것입니다. 스펙트럼(spectral) 접근 방식에 대해 먼저 설명하겠습니다.\n",
    "\n",
    "유클리드 영역에서 푸리에 변환은 순환 행렬의 고유 벡터로 구할 수 있으며, 이 행렬은 교환가능성(commutativity)으로 인해 공동으로 대각선화할 수 있다(jointly diagonalisable)는 것을 기억하세요. 따라서 모든 순환 행렬, 특히 미분(differential) 연산자는 일반 영역에서 푸리에 변환의 유추를 정의하는 데 사용할 수 있습니다. 리만 기하학에서는 라플라스 연산자(Laplacian operator)의 직교 고유 기저(orthogonal eigenbasis)를 사용하는 것이 일반적이며, 여기서는 이를 정의하겠습니다.\n",
    "\n",
    "이를 위해, 내재 경사 연산자 $∇ : \\mathcal{X} (Ω, \\mathbb{R}) → \\mathcal{X} (Ω, TΩ)$에 대한 정의를 상기하여 다양체에서 스칼라 필드의 가장 가파른 국부적 증가 방향을 나타내는 접선(tangent) 벡터 필드를 생성합니다. 비슷한 방식으로 발산 연산자(divergence operator) $∇^∗ : \\mathcal{X} (Ω, TΩ) → \\mathcal{X} (Ω, \\mathbb{R})$을 정의할 수 있습니다. 접선 벡터 필드를 다양체의 흐름으로 생각하면, 발산은 한 지점에서 필드의 순 흐름(net flow)을 측정하여 필드 '소스(sources)'와 '싱크(sinks)'를 구분할 수 있게 해줍니다. 두 연산자가 인접한 연산자임을 강조하기 위해 $∇^∗$(일반적인 div와 반대되는 표기법)를 사용합니다,\n",
    "\n",
    "$$\n",
    "    \\langle X, ∇x \\rangle = \\langle ∇^∗X, x \\rangle,\n",
    "$$\n",
    "\n",
    "여기서 스칼라 필드와 벡터 필드 사이의 내적 곱 (15)와 (16)을 사용합니다.\n",
    "\n",
    "라플라시안(미분 기하학에서는 라플라스-벨트라미 연산자(Laplace-Beltrami operator)라고도 함)는 $\\mathcal{X}(Ω)$에서 $∆ = ∇^*∇$로 정의되는 연산자로, 한 점 주변의 무한소 구(infinitesimal sphere)에서 함수의 평균과 점 자체에서의 함수 값의 차이로 해석할 수 있습니다. 열 확산(heat diffusion), 양자 진동(quantum oscillations), 파동 전파(wave propagation) 등 다양한 현상을 설명하는 데 사용되는 수학 물리학에서 가장 중요한 연산자 중 하나입니다. 여기서 중요한 점은 라플라시안 함수가 내재적(intrinsic)이어서 $Ω$의 아이소메트리(동형변환, isometries) 하에서 불변(invariant)이라는 점입니다.\n",
    "\n",
    ">이 해석을 통해 라플라시안도 등방성(isotropic)이라는 것이 분명해집니다. 4.6절에서 $∇^{\\ast} (A(u)∇)$ 형태의 이방성 라플라스 변환(anisotropic Laplacians)을 정의할 수 있음을 살펴볼 텐데, 여기서 $A(u)$는 국부 방향(local direction)을 결정하는 위치 의존(a position-dependent) 텐서입니다(Andreux et al., 2014; Boscaini et al., 2016b).\n",
    "\n",
    "라플라시안도 자기접합(self-adjoint)('대칭')이라는 것을 쉽게 알 수 있습니다,\n",
    "\n",
    "$$\n",
    "    \\langle∇x, ∇x\\rangle = \\langle x, ∆x\\rangle = \\langle∆x, x\\rangle.\n",
    "$$\n",
    "\n",
    "위 식에서 왼쪽의 이차식은 사실 이미 익숙한 디리클레 에너지(Dirichlet energy)입니다.\n",
    "\n",
    "$$\n",
    "    c^2 (x) = \\| ∇x \\|^2 = \\langle ∇x, ∇x \\rangle = \\int_Ω \\| ∇x(u)\\|^2_u du = \\int_Ω g_u(∇x(u), ∇x(u))du \n",
    "$$\n",
    "\n",
    "$x$의 평활도(smoothness)를 측정합니다.\n",
    "\n",
    "라플라시안 연산자는 다양체가 콤팩트한 경우(암묵적으로 가정하는 경우) 셀 수 있는 스펙트럼과 함께 다음과 같은 고유분해(eigedecomposition)을 인정합니다.\n",
    "\n",
    "$$\n",
    "    ∆_{\\varphi k} = λ_{k \\varphi k}, \\quad  k = 0, 1, .. .\n",
    "$$\n",
    "\n",
    "그리고 $∆$의 자기접합성(self-adjointness)으로 인해, 직교 고유 함수(eigenfunctions)인 $\\langle \\varphi_k, \\varphi_l \\rangle  = δ_{kl}$ 을 가집니다. 라플라시안 고유 기저(Laplacian eigenbasis)는 디리클레 에너지의 직교 최소자 집합으로도 구성할 수 있습니다.\n",
    "\n",
    "$$\n",
    "    \\varphi_{k+1} = \\arg \\min_\\varphi \\| ∇\\varphi \\|^2 \\quad \\text{ s.t. } \\quad \\| \\varphi \\| = 1 \\text{ and } \\langle \\varphi, \\varphi_j \\rangle  = 0\n",
    "$$\n",
    "\n",
    "$j = 0, . . . , k$에 대해, 이는 $Ω$에서 가장 평활한 직교 기저로 해석할 수 있습니다. 고유 함수(eigenfunctions) $\\varphi_0, \\varphi_1, ...$ 및 해당 고유값(eigenvalues) $0 = λ_0 ≤ λ_1 ≤ ...$은 고전적인 푸리에 변환에서 원자와 주파수의 유추로 해석할 수 있습니다.\n",
    "\n",
    ">실제로 $e^{iξu}$는 유클리드 라플라시안 $\\frac{d^2}{du^2}$의 고유 함수(eigenfunctions)입니다.\n",
    "\n",
    "이 직교 기준을 사용하면 $Ω$에서 제곱 적분 가능한(square-integrable) 함수를 푸리에 급수(Fourier series)로 확장할 수 있습니다. \n",
    "\n",
    "$$\n",
    "    x(u) = \\sum_{k≥0} \\langle x, \\varphi_k \\rangle \\varphi_k(u)\n",
    "$$\n",
    "\n",
    "여기서 $\\hat{x}_k = \\langle x, \\varphi_k \\rangle$는 푸리에 계수(Fourier coefficient) 또는 x의 (일반화된) 푸리에 변환이라고 합니다. 푸리에 급수를 자르면 다음과 같이 근사 오차가 발생하며, 이는 다음과 같이 경계가 지정될 수 있습니다(Aflalo and Kimmel, 2013).\n",
    "\n",
    "$$\n",
    "    \\Vert x - \\sum_{k=0}^{N} \\langle x, \\varphi_k \\rangle \\varphi_k \\Vert^2 ≤ \\frac{ \\| ∇x \\|^2}{λ_{N+1}}.\n",
    "$$\n",
    "\n",
    "Aflalo et al. (2015)는 라플라스 고유 기저가 다양체에서 매끄러운 신호를 표현하는 데 최적(optimal)이라는 것을 보여주었습니다.\n",
    "\n",
    ">이 푸리에 변환은 $Ω$의 소형화(compactness)로 인해 스펙트럼이 이산적(discrete)이므로 이산 인덱스를 갖습니다.\n",
    "\n",
    "### 다양체의 스펙트럼 컨볼루션\n",
    "Spectral Convolution on Manifolds\n",
    "\n",
    "스펙트럼 컨볼루션(Spectral convolution)은 신호 $x$와 필터 $θ$의 푸리에 변환의 곱으로 정의할 수 있습니다,\n",
    "\n",
    "$$\n",
    "    (x \\star θ)(u) = \\sum_{k≥0} (\\hat{x}_k - \\hat{θ}_k)\\varphi_k(u). \\tag{17}\n",
    "$$\n",
    "\n",
    "여기서는 비유클리드 컨볼루션을 정의(define)하는 방법으로, 고전적인 푸리에 변환의 특성(property)(컨볼루션 정리 (Convolution Theorem))을 사용합니다. 그 구조에 의해, 스펙트럼 컨볼루션은 내재적이며 따라서 아이소메트리 불변(isometry-invariant)입니다. 또한 라플라스 연산자는 등방성(isotropic)이므로 방향 감각이 없으며, 이러한 의미에서, 이웃 집계(neighbour aggregation)의 순열 불변성(permutation invariance)으로 인해 4.1절의 그래프에서 보았던 상황과 유사합니다.\n",
    "\n",
    "실제로, (17)을 직접 계산하는 것은 라플라스 변환을 대각선화해야 하기 때문에 비용이 엄청나게 많이 드는 것으로 보입니다. 더 큰 문제는 기하학적으로 불안정하다는 점입니다. 주파수가 높은 라플라시안 고유 함수는 도메인 Ω의 거의 등각에 가까운 섭동(near-isometric perturbations)에도 극적으로 변할 수 있습니다(그림 12 참조). 필터를 $\\hat{p}(∆)$ 형태의 스펙트럼 전달 함수(spectral transfer function)로 구현하면 보다 안정적인 솔루션을 얻을 수 있습니다,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "(\\hat{p}(∆)x)(u) & = \\sum_{k≥0} \\hat{p}(λ_k) \\langle x, \\varphi_k \\rangle \\varphi_k (u) \\tag{18} \\\\\n",
    "& = \\int_{Ω} x(v) \\sum_{k≥0} \\hat{p}(λ_k) \\varphi_k (v) \\varphi_k (u) dv \\tag{19}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "이는 두 가지 방식으로 해석할 수 있습니다. $\\hat{θ}_k = \\hat{p}(λ_k)$를 식별하는 스펙트럼 필터(spectral filter)(18) 또는 위치 의존 커널 $θ(u, v) = \\sum_{k≥0} \\hat{p}(λ_k) \\varphi_k (v) \\varphi_k (u)$를 갖는 공간 필터(spatial filter)(19)로 해석할 수 있습니다. 이 공식의 장점은 $\\hat{p}(λ)$를 적은 수의 계수(coefficients)로 파라미터화할 수 있으며, 다항식(polynomials) $\\hat{p}(λ) = \\sum_{l=0}^{r} α_lλ^l$과 같은 파라미터 함수를 선택하면 필터를 다음과 같이 스펙트럼 분해를 완전히 피하여 효율적으로 계산할 수 있다는 점입니다.\n",
    "\n",
    "$$\n",
    "    (\\hat{p}(∆)x)(u) = \\sum_{k≥0} \\sum^{r}_{l=0} α_lλ^l_k \\langle x, \\varphi_k \\rangle \\varphi_k (u) = \\sum^r_{l=0}α_l(∆^lx)(u),\n",
    "$$\n",
    "\n",
    "이 구조에 대해서는 섹션 4.6에서 더 자세히 설명하겠습니다.\n",
    "\n",
    ">푸리에 변환을 통해 표현되는 스펙트럼 컨볼루션을 기반으로 하는 기하학적 딥러닝 방법은 흔히 '스펙트럼(spectral)'이라고 불리며, 앞서 그래프의 맥락에서 보았던 '공간(spatial)' 방법과 반대되는 개념입니다. 이 두 가지 관점은 서로 동등(equivalent)할 수 있으므로 이러한 이분법(dichotomy)은 다소 인위적이며 완전히 적절하지 않습니다.\n",
    "\n",
    "### 다면체의 공간 컨볼루션\n",
    "Spatial Convolution on Manifolds\n",
    "\n",
    "두 번째 대안은 공식 (14)에서와 같이 서로 다른 지점에서 필터를 일치시켜 다면체(Manifolds)매니폴드에 컨볼루션을 정의하는 것입니다,\n",
    "\n",
    "$$\n",
    "    (x \\star θ)(u) = \\int_{T_uΩ} x(\\exp_u Y )θ_u(Y)dY, \\tag{20}\n",
    "$$\n",
    "\n",
    "여기서 지수 맵(exponential map)을 사용하여 탄젠트 공간에서 스칼라 필드 x의 값에 접근(access)해야 하며, 필터 $θ_u$는 각 지점의 탄젠트 공간에서 정의되므로, 위치에 따라 달라집니다. 필터를 내재적으로 정의하면, 이러한 컨볼루션은 균등 불변성(isometry-invariant)이 되는데, 이는 많은 컴퓨터 비전 및 그래픽 애플리케이션에서 중요하다고 언급한 속성입니다. \n",
    "\n",
    "그러나 4.2-4.3절의 이전 구성과 몇 가지 중요한 차이점에 주목할 필요가 있습니다. 첫째, 다양체는 일반적으로 균질(homogeneous) 공간이 아니기 때문에 한 지점에서 공유 필터(즉, 식 (20)의 $θ_u$가 아닌 모든 u에서 동일한 $θ$)를 정의한 다음 이동할 수 있는 전역 그룹 구조가 더 이상 존재하지 않습니다. 다양체에서 이 연산을 유추하려면 병렬 전송(parallel transport)-$T_uΩ$에서 함수로 정의된 공유 $θ$를 다른 $T_vΩ$에 적용할 수 있게하게 하는-이 필요합니다. 그러나 앞서 살펴본 바와 같이 이것은 일반적으로 $u$와 $v$ 사이의 경로에 따라 달라지므로, 필터를 이동하는 방식이 중요합니다. 셋째, 지수 맵은 국부적으로만 사용할 수 있으므로, 필터는 국부적이어야 하며, 주입 반경(injectivity radius)에 의해 경계가 지정되어야 합니다. \n",
    "넷째, 가장 결정적으로, $θ(X)$는, X가 추상적인 기하학적 객체인것 처럼, 계산에 사용할 수 없습니다. 계산에 사용하려면, $θ(X)$를 일부 국부 기저 $ω_u : \\mathbb{R}^s → T_uΩ$에 대해 $x = ω^{-1}_u (X)$의 $s$ 차원 좌표 배열로 표현해야 합니다. 이를 통해 컨볼루션(20)을 다음과 같이 다시 작성할 수 있습니다.\n",
    "\n",
    "$$\n",
    "    (x \\star θ)(u) = \\int_{[0,1]^s} x(\\exp_u (ω_uy))θ(y)dy, \\tag{21}\n",
    "$$\n",
    "\n",
    "를 단위 큐브에 정의된 필터와 함께 사용합니다. 지수 맵은 (측지법의 정의를 통해) 내재적이기 때문에 결과 컨볼루션은 아이소메트리 불변형(isometry invariant)입니다.\n",
    "\n",
    "그러나 이것은 암묵적으로 프레임 $ω_u$를 다른 다양체로 옮길 수 있다고 가정합니다(즉, $ω'_u = dη_u ◦ω_u$). 그러나 다양체 Ω만 주어졌을 때 이러한 프레임(또는 물리학 용어로 게이지(gauge))을 일관된 방식으로 구하는 것은 어려운 일입니다. 첫째, 매끄러운 전역 게이지가 존재하지 않을 수 있습니다: 이 경우는 다양체가 평행할 수 없는(parallelisable) 경우이며, 이 경우 매끄러운 비소실 접선 벡터장(smooth\n",
    "non-vanishing tangent vector field)을 정의할 수 없습니다. 둘째, 다양체에 대한 정식(canonical) 게이지가 없으므로, 이 선택은 임의적입니다. 컨볼루션은 $ω$에 의존하므로, 다른 게이지를 선택하면 다른 결과를 얻을 수 있습니다. \n",
    "\n",
    ">구 $\\mathbb{S}^2$는 평행이 불가능한(non-parallelisable) 다양체의 예로, 구어체로는 '카우릭(cowlick)을 만들지 않고는 털이 많은 공을 빗질할 수 없다'는 푸앵카레-호프 정리(Poincaré-Hopf Theorem)의 결과입니다. cowlick:(다른 부분의 머리카락들과 달리) 뻣뻣이 들고 일어나는 머리칼\n",
    "\n",
    "이것은 이론과 실제가 다른 경우입니다. 실제로는 다양체에서 일부 고유 스칼라 필드의 고유 기울기를 취하는 등 제한된 수의 특이점으로 대부분 매끄러운 프레임을 구축할 수 있다는 점에 유의해야 합니다. 또한 이러한 구조는 안정적입니다. 즉, 이러한 방식으로 구성된 프레임은 아이소메트릭 다양체(isometric manifolds)에서 동일하고 유사 아이소메트릭 다양체(approximately isometric ones)에서도 비슷합니다. 이러한 접근 방식은 실제로 다양체에 대한 딥 러닝의 초기 연구에서 사용되었습니다(Masci et al., 2015; Monti et al., 2017). \n",
    "\n",
    "그럼에도 불구하고 이 솔루션이 완전히 만족스럽지 않은 이유는 특이점 근처에서는 필터 방향(게이지에 대해 고정된 방식으로 정의됨)이 크게 달라져, 입력 신호와 필터가 매끄럽더라도 특징 맵이 매끄럽지 않게 되기 때문입니다. 또한, 어떤 지점 $u$에서 주어진 방향이 전혀 다른 지점 $v$에서 다른 방향과 동일하게 간주되어야 하는 명확한 이유가 없습니다. 따라서 실용적인 대안이 있음에도 불구하고, 다음에는 게이지 선택에 완전히 독립적인 보다 이론적으로 근거가 있는 접근 방식을 살펴볼 것입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8997b654",
   "metadata": {},
   "source": [
    "## 4.5 게이지 및 번들\n",
    "Gauges and Bundles\n",
    "\n",
    "탄젠트 공간의 프레임으로 정의한 게이지의 개념은 물리학에서 좀 더 일반적인 개념으로, 탄젠트 번들뿐만 아니라 모든 벡터 번들(vector bundle)에 대한 프레임을 나타낼 수 있습니다. 비공식적으로 벡터 번들은 다른 공간에 의해 매개변수화된 벡터 공간의 군집(family)을 나타내며, 기본 공간 $Ω$과 각 위치 $u ∈ Ω$에 부착된 동일한 벡터 공간(identical vector space) $\\mathbb{V}$ (섬유라고 함)로 구성됩니다(탄젠트 번들의 경우 탄젠트 공간 TuΩ이 됩니다). 대략적으로 말하자면, 다발은 국지적으로는 $u$를 중심으로 $Ω × \\mathbb{V}$의 곱으로 보이지만 전역적으로는 '뒤틀린(twisted)' 구조로 전체적으로 다른 구조를 가질 수 있습니다. 기하학적 딥러닝에서는 섬유를 사용하여 다양체 $Ω$의 각 지점에서 특징 공간(feature spaces)을 모델링할 수 있으며, 섬유의 치수는 특징 채널(feature channels)의 수와 동일합니다. 이러한 맥락에서 게이지 대칭(gauge symmetry)이라는 새롭고 흥미로운 종류의 대칭이 나타날 수 있습니다.\n",
    "\n",
    ">역사적으로 섬유 다발(fibre bundles)은 엘리 카르탕의 현대 미분 기하학에서 처음 등장했으며(카르탕은 섬유 다발을 명시적으로 정의하지는 않았지만), 1930년대에 위상학 분야에서 독립적인 객체로 발전했습니다.\n",
    "\n",
    "$S$차원 다양체 $Ω$와 이것의 탄젠트 다발(bundle) $TΩ$ 그리고 과 벡터장 $X : Ω → TΩ$(이 용어에서는 탄젠트 다발의 한 부분(section)이라고 함)을 다시 생각해 봅시다. 접선 다발에 대한 게이지 $ω$와 관련하여 $X$는 함수 $x : Ω → \\mathbb{R}^s$ 로 표현됩니다. 그러나 우리가 실제로 관심을 갖는 것은 기본 기하학적 객체(벡터장)이며, 함수 $x ∈ X (Ω, \\mathbb{R}^s )$로 표현되는 것은 게이지 ω의 선택에 따라 달라집니다. 게이지를 변경하면 표현되는 기본 벡터장을 보존하기 위해 x도 변경해야 한다는 것을 인식하는 것이 중요합니다.\n",
    "\n",
    "### 탄젠트 번들 및 구조 그룹\n",
    "Tangent bundles and the Structure group\n",
    "\n",
    "게이지를 변경할 때는 각 지점에 이전 게이지를 새 게이지에 매핑하는 반전(invertible) 행렬을 적용해야 합니다. 이 행렬은 각 지점의 모든 게이지 쌍에 대해 고유하지만, 다른 지점에서는 다를 수 있습니다. 다시 말해, 게이지 변환(gauge transformation)은 $\\mathfrak{g} : Ω → GL(s)$로 매핑하는 것으로, 여기서 $GL(s)$는 반전 가능한 $s × s$ 행렬의 일반 선형 그룹(general linear group)입니다. 이는 게이지 $ω_u : \\mathbb{R}^{s} → T_uΩ$에 작용하여 새로운 게이지 $ω'_u = ω_u ◦ \\mathfrak{g}_u : \\mathbb{R}^s → T_uΩ$을 생성합니다. 게이지 변환은 각 지점의 좌표 벡터 필드에 $x' (u) = \\mathfrak{g}_u^{-1} x(u)$를 통해 작용하여 새 게이지에 대한 $X$의 좌표 표현 $x'$을 생성합니다. 기본 벡터 필드는 변경되지 않습니다: \n",
    "\n",
    "$$\n",
    "    X(u) = ω'_u (x' (u)) = ω_u(\\mathfrak{g}_u\\mathfrak{g}^{-1}_u x(u)) = ω_u(x(u)) = X(u),\n",
    "$$\n",
    "\n",
    "가 바로 우리가 원했던 속성입니다. 보다 일반적으로 $GL(s)$의 표현 $ρ$에 따라 변환하는 기하학적 양의 필드가 있을 수 있는데, 예를 들어 $\\mathbf{A}'(u) = ρ_2(\\mathfrak{g}^{-1}_u)\\mathbf{A}(u) = ρ_1(\\mathfrak{g}_u)\\mathbf{A}(u)ρ_1(\\mathfrak{g}^{-1} u)$와 같이 변환하는 2-텐서(행렬) $\\mathbf{A}(u) ∈ \\mathbb{R}^{s×s}$의 필드를 예로 들어보겠습니다. 이 경우 게이지 변환 $g_u$는 $ρ(g_u)$를 통해 작용합니다. \n",
    "\n",
    "직교(orthogonal) 프레임, 오른손잡이(right-handed) 프레임 등과 같이 특정 속성을 가진 프레임으로 주의를 제한(restrict attention)하고 싶을 때가 있습니다. 당연히 우리는 그룹을 형성하는 몇 가지 속성 보존 변환 집합에 관심이 있습니다. 예를 들어 직교성을 보존하는 그룹은 직교 그룹 $O(s)$(회전 및 반사)이고, 방향성 또는 '양손잡이(handedness)'를 추가로 보존하는 그룹은 $SO(s)$(순수 회전)입니다. 따라서 일반적으로 우리는 번들의 구조 그룹(structure group)이라고 불리는 그룹 $\\mathfrak{G}$를 가지며, 게이지 변환은 맵 $\\mathfrak{g} : Ω → \\mathfrak{G}$입니다. 핵심 관찰 사항은 주어진 속성을 가진 모든 경우에서, 주어진 지점의 두 프레임에 대해 정확히 하나의 게이지 변환이 관련되어 있다는 것입니다.\n",
    "\n",
    "앞서 언급했듯이, 게이지 이론(gauge theory)은 접선 다발(tangent bundles)을 넘어 일반적으로 기본 공간 $Ω$의 구조와 차원이 반드시 관련되지 않는 벡터 공간의 다발을 고려할 수 있습니다. 예를 들어, 컬러 이미지 픽셀은 2D 격자에서 위치 $u ∈ Ω = \\mathbb{Z}^2$ 이고 RGB 공간에서 $x(u) ∈ \\mathbb{R}^3$이므로, 픽셀의 공간은 기본 공간 $\\mathbb{Z}^2$와 각 지점에 섬유 $\\mathbb{R}^3$이 연결된 벡터 번들로 볼 수 있습니다. RGB 이미지를 R, G, B(순서대로)에 대한 기저 벡터를 가진 게이지를 기준으로 표현하는 것이 일반적이므로 이미지의 좌표 표현은 $\\mathbf{x}(u) = (r(u), g(u), b(u))^{\\intercal}$와 같이 보입니다. 그러나 각 지점에서 사용 중인 프레임(채널 순서)을 기억하기만 하면, 각 위치에서 기저 벡터(색상 채널)를 독립적으로 순열할 수도 있습니다. 계산 연산으로 이것은 다소 무의미하지만, 곧 살펴보겠지만 게이지 대칭(이 경우 색상 간의 동등성)을 표현하고 이미지에 정의된 함수가 이 대칭을 존중하도록(각 색상을 동등하게 취급) 할 수 있기 때문에 RGB 색상 공간에 대한 게이지 변환에 대해 생각하는 것이 개념적으로 유용합니다. \n",
    "\n",
    ">$s$는 기본 공간 $Ω$의 차원을 나타내고 $d$는 섬유(fibre)의 차원을 나타냅니다. 탄젠트 번들의 경우 $d = s$는 기본 매니폴드의 차원입니다. RGB 이미지의 경우 $s = 2, d = 3$입니다.\n",
    "\n",
    ">이 예에서는 번들의 구조 그룹으로 3개 색상 채널의 순열인 $\\mathfrak{G} = Σ_3$을 선택했습니다. 색조 회전 $\\mathfrak{G} = SO(2)$와 같은 다른 선택도 가능합니다.\n",
    "\n",
    "다양체의 벡터장의 경우와 마찬가지로 RGB 게이지 변환은 이미지의 수치 표현(각 픽셀에서 RGB 값을 독립적으로 순열)을 변경하지만 기본 이미지는 변경하지 않습니다. 머신 러닝 애플리케이션에서는 이러한 이미지에 대해 신경망의 레이어로 구현된 함수 $f ∈ \\mathcal{F(X} (Ω))$를 구성하는 데 관심이 있습니다(예: 이미지 분류 또는 세그먼테이션 수행). 따라서 어떤 이유로든 이미지에 게이지 변환을 적용하려면 이미지의 의미를 보존하기 위해 함수 $f$(네트워크 레이어)도 변경해야 합니다. 간단하게 $1 × 1$ 컨볼루션, 즉 RGB 픽셀 $\\mathbf{x}(u) ∈ \\mathbb{R}^3$을 특징 벡터 $\\mathbf{y}(u) ∈ \\mathbb{R}^C$로 변환하는 맵을 생각해 보겠습니다. 기하학적 딥러닝 청사진에 따르면 출력은 그룹 표현 $ρ_{out}$(이 경우 구조 그룹 $\\mathfrak{G} = Σ_3$(RGB 채널 순열)의 $C$ 차원 표현)과 연관되며, 마찬가지로 입력은 표현 $ρ_{in}(\\mathfrak{g}) = \\mathfrak{g}$와 연관됩니다. 그런 다음 입력에 게이지 변환을 적용하면 선형 맵($1×1$ 컨볼루션) $f$ 를 변경해야 합니다 $f: \\mathbb{R}^3 → \\mathbb{R}^C$를 $f' = ρ^{-1}_{out}(\\mathfrak{g}) ◦ f ◦ ρ_{in}(\\mathfrak{g})$로 변경하여 출력 특징 벡터 $\\mathbf{y}(u) = f(\\mathbf{x}(u))$가 모든 지점에서 $\\mathbf{y}'(u) = ρ_{out}(\\mathfrak{g}_u)\\mathbf{y}(u)$처럼 변환되도록 합니다. 그 결과 다음을 확인합니다:\n",
    "\n",
    "$$\n",
    "    \\mathbf{y}' = f'(\\mathbf{x}') = ρ^{-1}_{out}(\\mathfrak{g})f(ρ_{in}(\\mathfrak{g})ρ^{-1}_{in}(g)\\mathbf{x}) = ρ^{-1}_{out}(\\mathfrak{g})f(\\mathbf{x}).\n",
    "$$\n",
    ".\n",
    "\n",
    ">여기서 $ρ^{-1}(\\mathfrak{g})$ 표기는 그룹 표현(행렬) $ρ(\\mathfrak{g})$의 역으로 이해해야 합니다.\n",
    "\n",
    "### 게이지 대칭\n",
    "Gauge Symmetries \n",
    "\n",
    "게이지 변환을 대칭으로 간주한다는 것은 게이지 변환으로 관련된 두 게이지를 동등한 것으로 간주한다는 의미입니다. 예를 들어, $\\mathfrak{G} = SO(d)$를 취하면, 두 개의 오른쪽 직교 프레임은 회전을 통해 다른 프레임에 매핑할 수 있으므로 동등한 것으로 간주됩니다. 즉, \"위\" 또는 \"오른쪽\"과 같은 구별된 로컬 방향이 없습니다. 마찬가지로, $\\mathfrak{G} = O(d)$(직교 그룹)인 경우, 왼쪽 및 오른쪽 직교 프레임은 모두 동등한 것으로 간주됩니다. 이 경우에도 선호하는 방향은 없습니다. 일반적으로, 우리는 그룹 $\\mathfrak{G}$와 모든 점 $u$에서 프레임의 집합을 고려할 수 있으며, 그 중 두 개에 대해 한 프레임을 다른 프레임에 매핑하는 고유한 $\\mathfrak{g}(u) ∈ \\mathfrak{G}$가 있습니다.\n",
    "\n",
    "기하학적 딥러닝 청사진에서 게이지 변환을 대칭으로 간주할 때, 우리는 $Ω$에 정의되고 게이지에 대해 표현되는 신호에 작용하는 함수 $f$가 이러한 변환과 등변수여야 한다는 점에 관심이 있습니다. 구체적으로, 이는 입력에 게이지 변환을 적용하면 출력도 동일한 변환을 거쳐야 함을 의미합니다(아마도 $\\mathfrak{G}$의 다른 표현을 통해 작용할 수 있음). 앞서 게이지를 변경하면 함수 $f$도 변경되어야 한다고 언급했지만, 게이지 등변수 맵의 경우 그렇지 않습니다. 게이지를 변경하면 매핑이 불변으로 남습니다. 이를 확인하기 위해 RGB 색 공간 예시를 다시 살펴보겠습니다. 맵 $f : \\mathbb{R}^3 → \\mathbb{R}^{C}$ 맵은 $f ◦ρ_{in}(\\mathfrak{g}) = ρ_{out}(\\mathfrak{g}) ◦ f$이면 등변수(equivariant)이지만, 이 경우 $f$에 적용된 게이지 변환은 $ρ^{-1}_{out}(\\mathfrak{g}) ◦ f ◦ ρ_{in}(\\mathfrak{g}) = f$로 아무런 영향을 미치지 않습니다. 즉, 그래프의 경우 입력 노드가 순열된 방식과 관계없이 동일한 함수를 적용한 것과 마찬가지로 게이지 등변수 맵(gauge equivariant map)의 좌표식은 게이지와 무관합니다. 그러나 게이지 변환은 그래프나 지금까지 다룬 다른 예제와 달리 $Ω$이 아닌 각 특징 벡터 $\\mathbf{x}(u)$에 대해 각 $Ω ∈ u$에 대해 $\\mathfrak{g}(u) ∈ G$로 변환하여 개별적으로 작용합니다. \n",
    "\n",
    "더 큰 공간 지원(larger spatial support)을 가진 다양체에서 필터를 살펴볼 때 더 많은 고려 사항이 필요합니다. 먼저 스칼라 필드에서 $s$차원 다양체 $Ω$의 스칼라 필드로의 매핑 $f : \\mathcal{X} (Ω, \\mathbb{R}) → \\mathcal{X} (Ω, \\mathbb{R})$의 쉬운 예를 생각해 보겠습니다. 벡터나 다른 기하학적 양과 달리, 스칼라에는 방향이 없으므로, 스칼라 필드 $x ∈ \\mathcal{X} (Ω, \\mathbb{R})$는 게이지 변환에 불변(invariant)입니다($ρ(g) = 1$이라는 사소한 표현에 따라 변환됨). 따라서 스칼라 필드에서 스칼라 필드로의 모든 선형 맵은 게이지 등변수(gauge equivariant)(또는 불변수(invariant), 이 경우 동일)입니다. 예를 들어, 위치 의존 필터 $θ : Ω × Ω → \\mathbb{R}$을 사용하여 컨볼루션과 유사한 연산으로 (19)와 유사하게 $f$를 작성할 수 있습니다,\n",
    "\n",
    "$$\n",
    "    (x \\star θ)(u) = \\int_Ω θ(u, v)x(v)dv. \\tag{22}\n",
    "$$\n",
    "\n",
    "이는 각 지점에서 잠재적으로 다른 필터 $θ_u = θ(u, \\cdot)$가 있음을 의미하며, 즉 게이지 대칭만으로는 제공하지 않는, 공간 가중치 공유(spatial weight sharing)가 없음을 의미합니다.\n",
    "\n",
    "이제 벡터 필드에서 벡터 필드로의 매핑 $f : \\mathcal{X} (Ω, TΩ) → \\mathcal{X} (Ω, TΩ)$의 더 흥미로운 경우를 생각해 봅시다. 게이지와 관련하여 입력 및 출력 벡터 필드 $X, Y ∈ \\mathcal{X}(Ω, TΩ)$는 벡터 값 함수 $\\mathbf{x, y} ∈ \\mathcal{X} (Ω, \\mathbb{R}^s )$입니다. 이러한 함수 사이의 일반적인 선형 맵은 스칼라에 사용한 것과 동일한 방정식(22)을 사용하여 스칼라 커널을 행렬 값 $Θ : Ω × Ω → \\mathbb{R}^{s×s}$ 로 대체하기만 하면 작성할 수 있습니다. 행렬 $Θ(u, v)$는 $T_vΩ$의 탄젠트 벡터를 $T_uΩ$의 탄젠트 벡터에 매핑해야 하지만, 이 점들은 서로 다른 게이지(e different gauges)를 가지므로 임의로 그리고 독립적으로(arbitrarily and independently) 변경할 수 있습니다. 즉, 필터는 모든 $u, v ∈ Ω$에 대해 $Θ(u, v) = ρ^{-1} (\\mathfrak{g}(u))Θ(u, v)ρ(\\mathfrak{g}(v))$를 만족해야 하며, 여기서 ρ는 벡터에 대한 G의 작용을 나타내며, s × s 회전 행렬에 의해 주어집니다. $\\mathfrak{g}(u)$와 $\\mathfrak{g}(v)$는 자유롭게 선택할 수 있으므로 이는 필터에 대한 지나치게 강력한 제약 조건입니다.\n",
    "\n",
    ">실제로 이 경우 $Θ$는 0이어야 합니다.\n",
    "\n",
    "더 나은 접근법은 먼저 연결을 통해 벡터를 공통 접선 공간으로 전송한 다음 한 지점에서만 단일 게이지 변환에 대해 게이지 등식(gauge equivariance)을 부과하는 것입니다. (22) 대신 벡터 필드 사이의 맵을 다음과 같이 정의할 수 있습니다,\n",
    "\n",
    "$$\n",
    "    (\\mathbf{x} \\star Θ)(u) = \\int_Ω Θ(u, v)ρ(\\mathfrak{g}_{v→u})\\mathbf{x}(v)dv, \\tag{23}\n",
    "$$\n",
    "\n",
    "여기서 $\\mathfrak{g}{v→u} ∈ \\mathfrak{G}$는 이 두 점을 연결하는 측지선을 따라 $v$에서 $u$로 평행 이동하는 것을 나타내며, 그 표현 $ρ(\\mathfrak{g}_{v→u})$는 벡터가 점 사이를 이동할 때 벡터를 회전시키는 $s × s$ 회전 행렬입니다. 이 측지선은 로컬에서만 참인 고유한 것으로 가정하므로 필터는 로컬 지원(local support)을 가져야 합니다. 게이지 변환 $\\mathfrak{g}_u$에서, 이 요소는 $\\mathfrak{g}_{u→v} \\mapsto \\mathfrak{g}^{-1}_{u} \\mathfrak{g}_{u→v}\\mathfrak{g}_v$로 변환되고, 필드 자체는 $\\mathbf{x}(v) \\mapsto ρ(\\mathfrak{g}v)\\mathbf{x}(v)$로 변환됩니다. 필터가 구조 그룹 표현 $Θ(u, v)ρ(\\mathfrak{g}_u) = ρ(\\mathfrak{g}_u)Θ(u, v)$와 통근(commutes)하는 경우, 방정식 (23)은 게이지 등변수 컨볼루션(gauge-equivariant convolution)을 정의하며, 앞서 말한 변환 아래서 다음과 같이 변환됩니다. \n",
    "\n",
    "$$\n",
    "    (\\mathbf{x}' \\star Θ)(u) = ρ^{-1} (\\mathfrak{g}_u)(\\mathbf{x} \\star Θ)(u).\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "268affe1",
   "metadata": {},
   "source": [
    "## 4.6 기하학적 그래프 및 메시\n",
    "Geometric graphs and Meshes\n",
    "\n",
    "기하학적 그래프(geometric graphs)(즉, 어떤 기하학적 공간에서 구현할 수 있는 그래프)와 메시(meshes)를 통해 다양한 기하학적 영역에 대한 논의를 마무리하겠습니다. 기하학적 영역의 '5G'에서 메쉬는 그래프와 다양체의 중간에 속하며, 많은 면에서 그래프와 유사하지만 추가 구조를 통해 연속체와 유사하게 취급할 수도 있습니다. 이러한 이유로 메시를 독립된 객체로 간주하지 않으며, 실제로 이 섹션에서 메시를 위해 도출한 많은 구조가 일반 그래프에도 직접 적용 가능하다는 점을 강조할 것입니다.\n",
    "\n",
    "4.4절에서 이미 언급했듯이 2차원 다양체(서페이스(surfaces))는 3D 오브젝트(또는 더 정확하게는 그러한 오브젝트의 경계면)를 모델링하는 일반적인 방법입니다. 컴퓨터 그래픽 및 비전 애플리케이션에서 이러한 표면은 종종 삼각형 메쉬(triangular meshes)로 이산화되는데, 이는 삼각형의 가장자리를 따라 삼각형끼리 붙여서 얻은 표면의 조각 단위 평면 근사치라고 대략적으로 생각할 수 있습니다. 따라서 메쉬는 추가적인 구조를 가진 (방향이 없는) 그래프입니다. 노드와 에지 외에도 메쉬 $\\mathcal{T = (V, E, F)}$에는 삼각형 면을 형성하는 노드 삼중쌍이 정렬되어 있습니다. $\\mathcal{F} = \\{(u, v, q) : u, v, q ∈ \\mathcal{V}$ 및 $(u, v),(u, q),(q, v) ∈ E\\}$; 노드의 순서에 따라 면의 방향이 정의됩니다.\n",
    "\n",
    ">삼각형 메쉬는 단순 복합체(simplicial complexes)로 알려진 위상 구조의 예입니다.\n",
    "\n",
    "또한 각 에지는 정확히 두 개의 삼각형이 공유하며, 각 노드에 접하는 모든 삼각형의 경계는 에지의 단일 루프를 형성한다고 가정합니다. 이 조건은 각 노드 주변의 1-홉(1-hop) 이웃이 디스크와 같다(disk-like)는 것을 보장하며, 따라서 메시가 이산 다양체(discrete manifold)를 구성하고 이러한 메시를 매니폴드 메시라(manifold meshes)고 합니다. 리만 다양체와 유사하게 메시에서 메트릭(metric)을 정의할 수 있습니다. 가장 간단한 예로, 메시 노드 $\\mathbf{x}_1, . . . , \\mathbf{x}_n$의 임베딩을 유도하고, 가장자리의 유클리드 길이인 $\\ell_{uv} = \\| \\mathbf{x}_u-\\mathbf{x}_v \\|$로 표현할 수 있습니다. 이러한 방식으로 정의된 메트릭은 삼각형 부등식(triangle inequality)과 같은 속성, 즉 임의의 $(u, v, q) ∈ F$ 및 임의의 에지 조합에 대해 $\\ell_{uv} ≤ \\ell_{uq} + \\ell_{vq}$ 형식의 표현식을 자동으로 만족합니다. $\\ell$로만 표현할 수 있는 모든 특성은 내재적이며, $\\ell$를 보존하는 메쉬의 변형은 아이소메트리(isometry)입니다. 이러한 개념은 4.4절의 논의에서 이미 독자들에게 친숙한 개념입니다.\n",
    "\n",
    ">다양체(위쪽) 및 비-다양체(non-manifold)(아래쪽) 가장자리와 노드의 예입니다. 경계가 있는 다양체의 경우, 정확히 하나의 삼각형에 속하는 경계 가장자리(boundary\n",
    "edges)를 추가로 정의합니다. \n",
    "\n",
    "### 라플라시안 행렬\n",
    "Laplacian matrices\n",
    "\n",
    "그래프를 다룰 때와 유사하게, 각 노드가 $d$차원 특징 벡터와 연결된 $n$개의 노드가 있는 (매니폴드) 메시를 가정하고, 이를 (임의의 순서를 가정하여) $n×d$ 행렬 $\\mathbf{X}$로 배열할 수 있다고 가정해 보겠습니다. 특징(features)은 노드의 기하학적 좌표뿐만 아니라 색상, 법선(normals) 등과 같은 추가 속성을 나타내거나, 기하학적 그래프로 분자를 모델링하는 화학 같은 특정 애플리케이션에서 원자 번호와 같은 속성을 나타낼 수 있습니다. \n",
    "\n",
    "먼저 메시의 스펙트럼 컨볼루션(17)을 살펴봅시다. 독자들에게 라플라시안 연산자에서 발생한다는 것을 상기시켜 드립니다. 메시를 기저 연속 표면의 이산화라고 생각하면 라플라스 연산자를 다음과 같이 이산화할 수 있습니다.\n",
    "\n",
    "$$\n",
    "    (\\mathbf{∆X})_u = \\sum_{v∈N_u} w_{uv}(\\mathbf{x}_u - \\mathbf{x}_v), \\tag{24}\n",
    "$$\n",
    "\n",
    "또는 행렬-벡터 표기법에서는, $n × n$ 대칭 행렬 $\\mathbf{∆ = D - W}$로 표시하며, 여기서 $\\mathbf{D} = \\text{diag}(d_1, . . . , d_n)$를 차수 행렬(degree matrix)이라고 하고 $du = \\sum_v w_{uv}$를 노드 $u$의 차수(degree)라고 합니다. 방정식 (24)는 이웃 특징의 국부 순열 등변수 집계(local permutation-invariant aggregation) $φ(\\mathbf{x}u, \\mathbf{X}_{N_u}) = d_u \\mathbf{x}_u - \\sum_{v∈N_u} w_{uv}x_v$를 수행하며, $\\mathbf{F(X) = ∆X}$는 사실 그래프에서 순열 등변수 함수를 구축하는 일반적인 청사진 (13)의 인스턴스라는 것을 쉽게 알 수 있습니다.\n",
    "\n",
    "(24)의 라플라시안 정의에서 메시에만 국한(specific to meshes)된 것은 아니며, 사실 이 구성은 임의의 그래프에서도 유효하며, 에지 가중치는 인접 행렬 $\\mathbf{W = A}$, 즉 $(u, v) ∈ E$일 경우 $w_{uv} = 1$, 그렇지 않으면 0이 됩니다. 이러한 방식으로 구성된 라플라시안 그래프는 단순히(merely) 그래프의 연결 구조를 포착한다는 사실을 반영하여 조합적(combinatorial) 그래프라고 부르기도 합니다. 기하학적 그래프(반드시 메쉬의 추가 구조를 갖지는 않지만, 노드에 에지 길이 형태의 메트릭을 유도하는 공간 좌표가 있는 그래프)의 경우 메트릭과 반비례하는(inversely related) 가중치를 사용하는 것이 일반적입니다(예: $w_{uv} ∝ e^{-\\ell_{uv}}$ .\n",
    "\n",
    ">이 경우 차수는 이웃의 수와 같습니다.\n",
    "\n",
    ">그래프가 방향성인 경우 해당 라플라시안 그래프는 비대칭(non-symmetric)입니다.\n",
    "\n",
    "메시에서는 면이 제공하는 추가 구조를 활용하고, 코탄젠트 공식을 사용하여 방정식 (24)에서 에지 가중치를 정의할 수 있습니다(Pinkall and Polthier, 1993; Meyer et al., 2003). \n",
    "\n",
    "$$\n",
    "    w_{uv} = \\frac{\\text{cot}∠_{uqv} + \\text{cot}∠_{upv}}{2a_u} \\tag{25}\n",
    "$$\n",
    "\n",
    "여기서 $∠_{uqv}$ 및 $∠_{upv}$는 공유 에지$(u, v)$의 반대쪽 삼각형$(u, q, v)$과 $(u, p, v)$의 두 각도이며, $a_u$는 로컬 영역(area) 요소로, 일반적으로 노드 $u$를 공유하는 삼각형$(u, p, q)$의  무게 중심(barycenters) 위에 구축된 다각형의 영역으로 계산되며 $a_u = \\frac{1}{3} \\sum_{v,q:(u,v,q)∈\\mathcal{F}} a_{uvq}$로 주어집니다.\n",
    "\n",
    ">이 공식의 최초 사용은 1949년 캘텍 전기 아날로그 컴퓨터에서 PDEs를 풀기 위해 이 공식을 개발한 맥닐(MacNeal)의 박사 학위 논문으로 거슬러 올라갑니다.\n",
    "\n",
    "코탄젠트 라플라스 행렬은 여러 가지 편리한 특성을 가지고 있음을 보여줄 수 있습니다(예: Wardetzky et al. (2007) 참조): 양의 반정밀도(positive-semidefinite) 행렬이며, $∆ < 0$이므로 음이 아닌 고유값(non-negative eigenvalues) $λ_1 ≤ . . . ≤ λ_n$을 가지며, 이는 주파수에 대한 비유로 볼 수 있으며, 이것은 대칭(symmetric)이므로 직교 고유 벡터(orthogonal eigenvectors)를 가지며, 로컬입니다(즉,, ($\n",
    "\\mathbf{∆X})_u$의 값은 1홉(1-hop) 이웃인 $\\mathcal{N}_u$에만 의존합니다). 아마도 가장 중요한 특성은 메쉬가 무한히 세분화(refined)될 때, 코탄젠트 메쉬 라플라시안 행렬 $\\mathbf{∆}$이 연속 연산자 $\\mathbf{∆}$에 수렴하는 것입니다(Wardetzky, 2008). 따라서 방정식 (25)는 4.4절의 리만 다양체에서 정의된 라플라스 연산자의 적절한 이산화(discretisation)를 구성합니다.\n",
    "\n",
    ">예를 들어 삼각형이 병적(pathological)으로 변하는 것을 방지하기 위해 정제에 몇 가지 기술적 조건을 부과해야 합니다. 그러한 예 중 하나는 독일어로 '슈바르츠셔 스티펠(슈바르츠의 장화, (Schwarzscher Stiefel))' 또는 영문학에서 '슈바르츠 랜턴'으로 알려진 원통의 기괴한 삼각형으로, 1880년 코시-슈바르츠(Cauchy-Schwarz) 부등식의 명성으로 유명한 독일 수학자 헤르만 슈바르츠가 제안한 것입니다. (pathological: 수학에서는 수학적 현상이 어떤 직관에 반하는 경우, 그 현상을 병리적 현상이라고 부르기도 합니다.)\n",
    "\n",
    "라플라시안도 내재적일 것으로 예상하지만, 이는 방정식 (25)에서 명확하지 않으며, 이산 메트릭(discrete metric) $\\ell$의 관점에서 코탄젠트 가중치를 완전히 다음과 같이 표현하려면 약간의 노력이 필요합니다. \n",
    "\n",
    "$$\n",
    "    w_{uv} = \\frac{-\\ell^2_{uv} + \\ell^2_{vq} + \\ell^2_{uq}}{8a_{uvq}} + \\frac{-\\ell^2_{uv} + \\ell^2_{vp} + \\ell^2_{up}}{8a_{uvq}}\n",
    "$$\n",
    "\n",
    "여기서 삼각형 $a_{ijk}$의 면적은 다음과 같이 주어집니다.\n",
    "\n",
    "$$\n",
    "    a_{uvq} = \\sqrt{s_{uvq}(s_{uvq} - \\ell_{uv})(s_{uvq} - \\ell_{vq})(s_{uvq} - \\ell_{uq})}\n",
    "$$\n",
    "\n",
    "를 $s_{uvq} = \\frac{1}{2} (\\ell_{uv} + \\ell_{uq} + \\ell_{vq})$와 헤론의 반원근 공식(Heron’s semiperimeter formula)을 사용하여 계산합니다. 이것은 라플라시안(및 그와 관련된 모든 양(quantities), 예를 들어 고유 벡터 및 고유값)에 기하학 처리 및 컴퓨터 그래픽에서 매우 사랑받는 속성인 아이소메트리 불변성(isometry invariance)을 부여합니다(왕과 솔로몬(2019)의 훌륭한 리뷰 참조): 메트릭 l에 영향을 주지 않는 메시의 변형(메시의 가장자리를 '늘리거나(stretch)' '압박(squeeze)'하지 않는)은 라플라시안을 변화시키지 않습니다.\n",
    "\n",
    "마지막으로, 이미 알아차렸듯이 라플라시안 (25)의 정의는 합계의 형태로 집계를 포함하기 때문에 $\\mathcal{N}_u$의 노드 순열에 불변(invariant)합니다. 일반 그래프에서는 이웃의 정식 순서가 없기 때문에 이것은 필요악이지만, 메시에서는 1홉 이웃을 특정 방향(예: 시계 방향)에 따라 정렬할 수 있으며, 유일한 모호성은 첫 번째 노드의 선택입니다. 따라서 가능한 순열 대신 주기적 이동(cyclic shifts)(회전)을 고려해야 하는데, 이는 4.5절에서 설명한 $SO(2)$ 게이지 변환에서 발생하는 모호성에 직관적으로 대응(corresponds)합니다. 고정 게이지의 경우, 이방성 라플라스(anisotropic Laplacian) 변환을 정의할 수 있습니다. 이는 가중치 $w_{uv}$ 또는 메티릭 변화를 위해 국부 방향과 양에 대하여 민감합니다. 이러한 종류의 구조는 Andreux 외(2014)의 형상 기술자(shape descriptors) 설계에 사용되었으며, Boscaini 외(2016b)의 초기 메시 기하학적 딥 러닝 아키텍처와 Boscaini 외(2016a)의 메시 기하학적 딥 러닝 아키텍처에서 사용되었습니다. \n",
    "\n",
    ">라플라시안 기반 필터는 등방성(isotropic)입니다. 평면에서 이러한 필터는 방사형(radial) 대칭을 갖습니다.\n",
    "\n",
    "### 메시의 스펙트럼 분석\n",
    "Spectral analysis on meshes\n",
    "\n",
    "라플라스 행렬을 대각선화하는 직교 고유 벡터(orthogonal eigenvectors) $Φ = (\\varphi_1, . . . , \\varphi_n)$은 라플라시안 행렬 $\\mathbf{(∆ = ΦΛΦ^{\\intercal}}$, 여기서 $\\mathbf{Λ} = \\text{diag}(λ_1, . . . , λ_n)$은 라플라스 고유값의 대각선 행렬입니다.)을 대각화 합니다. 이것은 푸리에 기저(Fourier basis)의 비유클리드(non-Euclidean) 유추로 사용되어, 각 푸리에 변환의 곱으로 메시에서 스펙트럼 컨볼루션(spectral convolution)을 수행할 수 있습니다,\n",
    "\n",
    "$$\n",
    "    \\mathbf{X \\star θ = Φ} \\text{diag}\\mathbf{(Φ^{\\intercal}θ)(Φ^{\\intercal}X) = Φ }\\text{diag}(\\mathbf{\\hat{θ})\\hat{X}},\n",
    "$$\n",
    "\n",
    "여기서 필터 $\\hat{θ}$는 푸리에 영역에서 직접 설계됩니다. 다시 말하지만, 이 공식의 어떤 것도 메시에만 국한된 것이 아니며, 일반 (방향이 없는) 그래프의 라플라시안 행렬을 사용할 수 있습니다. 컨볼루션에 대한 이러한 스펙트럼(spectral) 정의를 활용하여 CNN을 그래프로 일반화하고 싶은 유혹이 있으며, 실제로 이 글의 저자 중 한 명인 Bruna 외(2013)가 이를 수행했습니다. 그러나 비유클리드 푸리에 변환은 기본 메시 또는 그래프의 사소한 섭동(perturbations)에 매우 민감하므로(4.4절의 그림 12 참조) 고정된 도메인에서 서로 다른 신호를 처리해야 할 때만 사용할 수 있으며, 다른 도메인에 걸쳐 일반화하려는 경우에는 사용할 수 없습니다. 안타깝게도 많은 컴퓨터 그래픽과 비전 문제는 후자의 범주에 속하며, 한 세트의 3D 모양(메시)으로 신경망을 훈련하고 다른 세트에서 테스트하기 때문에, 푸리에 변환 기반 접근 방식은 부적절합니다. \n",
    "\n",
    ">그래프가 방향이 없는 것으로 가정한다는 사실이 중요합니다. 이 경우 라플라시안 그래프는 대칭이며 직교 고유 벡터를 갖습니다.\n",
    "\n",
    "4.4절에서 언급했듯이, 라플라시안 행렬에 일부 전달 함수 $\\hat{p}(λ)$를 적용하는 (18) 형태의 스펙트럼 필터를 사용하는 것이 바람직합니다,\n",
    "\n",
    "$$\n",
    "    \\hat{p}(\\mathbf{∆)X} = \\mathbf{Φ}\\hat{p}\\mathbf{(Λ)Φ^{\\intercal}X} = \\mathbf{Φ} \\text{diag}(\\hat{p}(λ_1), . . . , \\hat{p}(λ_n))\\mathbf{X}. \n",
    "$$\n",
    "\n",
    "$\\hat{p}$를 행렬-벡터 곱으로 표현할 수 있는 경우, $n × n$ 행렬 $∆$의 고유분해(eigendecomposition)는 완전히 피할 수 있습니다. 예를 들어, Defferrard 등(2016)은 차수 r의 다항식(polynomials)을 필터 함수로 사용했습니다,\n",
    "\n",
    "$$\n",
    "    \\hat{p}(∆)\\mathbf{X} = \\sum^r_{k=0} α_k∆^k\\mathbf{X} = α_0\\mathbf{X} + α_1∆\\mathbf{X} + . . . + α_r∆^r\\mathbf{X},\n",
    "$$\n",
    "\n",
    "는 $n × d$ 특징(feature) 행렬 $X$에 $n × n$ 라플라시안 행렬을 $r$번 곱하는 것과 같습니다. 라플라스 행렬은 일반적으로 희소(sparse)하기 때문에(0이 아닌 요소가 $O(|\\epsilon|)$인 경우) 이 연산은 $O(|\\epsilon|dr) ∼ O(|\\epsilon|)$의 낮은 복잡도를 갖습니다. 또한 라플라시안도 국소적이므로 차수 $r$의 다항식 필터는 $r$ 홉(r-hop) 이웃에 국한됩니다.\n",
    "\n",
    ">일반적인 경우, 고유 분해의 복잡도는 $\\mathcal{O}(n^3)$입니다.\n",
    "\n",
    ">메시는 거의 규칙적인 그래프로, 각 노드에 $\\mathcal{O}(1)$개의 이웃이 있어 $∆$에서 $\\mathcal{O}(n)$개의 영점이 아닌 그래프가 됩니다.\n",
    "\n",
    "그러나 필터의 실제 지원(즉, 필터가 커버하는 반경)이 메시의 해상도(resolution)에 따라 달라지기 때문에, 메시를 다룰 때는 이 정확한 속성이 단점이 될 수 있습니다. 메쉬는 기본 연속 표면(some underlying continuous surface)의 이산화(discretisation)에서 발생하며, 동일한 오브젝트를 나타내는 두 개의 서로 다른 메쉬 $\\mathcal{T}$와 $\\mathcal{T}'$이 있을 수 있다는 점을 염두에 두어야 합니다. 더 미세한(finer) 메시에서는 더 거친 메시보다 더 큰 이웃을 사용해야 할 수 있습니다(따라서 필터의 차수 $r$도 더 커집니다).\n",
    "\n",
    "이러한 이유로 컴퓨터 그래픽 응용 프로그램에서는 해상도에 독립적(resolution-independent)이기 때문에 합리적인 필터(rational filters)를 사용하는 것이 더 일반적입니다. 이러한 필터를 정의하는 방법에는 여러 가지가 있으며(예: Patanè (2020) 참조), 가장 일반적인 방법은 $\\frac{λ-1}{λ+1}$ 과 같은 일부 유리 함수의 다항식으로 정의하는 것입니다. 더 일반적으로는, 실선(real line)을 복소 평면(complex plane)의 단위 원(unit circle)에 매핑하는 Cayley 변환(Cayley transform) $\\frac{λ-i}{λ+i}$와 같은 복소 함수를 사용할 수 있습니다. Levie 등(2018)은 복소 계수(complex coefficients) $α_l ∈ \\mathbb{C}$를 갖는 실수 유리 함수인 케일리 다항식(Cayley polynomials)으로 표현되는 스펙트럼 필터를 사용했습니다,\n",
    "\n",
    "$$\n",
    "    \\hat{p}(λ) = Re \\left( \\sum^r_{l=0} α_l \\left( \\frac{λ - i}{λ + i}\\right)^l\\right). \n",
    "$$\n",
    ".\n",
    "\n",
    ">케일리 변환은 뫼비우스 변환(Möbius transformation)의 특별한 경우입니다. 라플라시안(양의 반정밀도 행렬(positive-semindefinite matrix))에 적용하면 음이 아닌 고유값(non-negative eigenvalues)을 복소 반원(complex half-circle)에 매핑합니다. \n",
    "\n",
    "행렬에 적용할 때, 케일리 다항식(Cayley polynomial)을 계산하려면 행렬 반전(matrix inversion)이 필요합니다,\n",
    "\n",
    "$$\n",
    "    \\hat{p}(∆) = Re \\left( \\sum^r_{l=0} α_l(∆ - iI)^l (∆ + iI)^{-l} \\right),\n",
    "$$\n",
    "\n",
    "이는 선형 복잡성(linear complexity)으로 대략 수행(carried out approximately)될 수 있습니다. 다항식 필터와 달리, 유리수 필터(rational filters)는 국부적 지지대가 없지만 지수 붕괴(exponential decay)가 있습니다(Levie et al., 2018). 푸리에 변환의 직접 계산과 비교했을 때 중요한 차이점은, 다항식 필터와 유리 필터가 기본 그래프 또는 메시의 대략적인 등각 투영 변형(approximate isometric deformations)에서도 안정적이라는 점입니다. 이러한 종류의 다양한 결과는 Levie 등(2018, 2019), Gama 등(2020), Kenlay 등(2021)에서 보여주었습니다.\n",
    "\n",
    ">신호 처리에서 다항식 필터(polynomial filters)는 유한 임펄스 응답((finite impulse response) FIR)이라고 하고, 유리수 필터(rational filters)는 무한 임펄스 응답((infinite impulse response) IIR)이라고 합니다.\n",
    "\n",
    "### 연산자 및 함수형 맵으로서의 메시 \n",
    "Meshes as operators and Functional maps\n",
    "\n",
    "함수형 지도의 패러다임은 메쉬를 연산자(operators)로 생각할 것을 제안합니다. 앞으로 설명하겠지만, 이를 통해 메시의 추가 구조를 활용하여 더 흥미로운 유형의 불변성(invariance)을 얻을 수 있습니다. 논의의 목적을 위해 메쉬 $\\mathcal{T}$가 좌표 $\\mathcal{X}$를 가진 임베디드 노드 위에 구축되었다고 가정합니다. 라플라시안과 같은 내재 연산자를 구축하면, 메쉬의 구조를 완전히 인코딩하고 메쉬를 복구할 수 있음을 보여줄 수 있습니다(Zeng et al. (2012)에서 볼 수 있듯이 등각 임베디드(isometric embedding)까지). 이는 다른 연산자에서도 마찬가지이므로(예: Boscaini et al. (2015), Corman et al. (2017), Chern et al. (2018) 참조), 메시의 표현으로 일반 연산자 또는 $n × n$ 행렬 $\\mathbf{Q}(\\mathcal{T}, \\mathbf{X})$를 가정하겠습니다.\n",
    "\n",
    "이러한 관점에서 4.1절에서 논의한 $f(\\mathbf{X}, \\mathcal{T})$ 형태의 학습 함수(learning functions)에 대한 논의는 $f(\\mathbf{Q})$ 형태의 학습 함수로 바꿔 표현할 수 있습니다. 그래프 및 집합과 마찬가지로 메시의 노드에도 정식 순서(canonical ordering)가 없으므로 메시의 함수는 모든 순열 행렬(permutation matrix) P에 대해, 순열 불변성(permutation invariance) 또는 등분(equivariance) 조건을 만족해야 합니다,\n",
    "\n",
    "$$\n",
    "f(\\mathbf{Q}) = f(\\mathbf{PQP}^{\\intercal})\n",
    "\\\\\n",
    "\\mathbf{PF(Q) = F(PQP^{\\intercal})} \n",
    "$$\n",
    "\n",
    "그러나 일반 그래프에 비해, 이제 메시가 기본 연속 곡면(underlying continuous surface) $Ω$의 이산화(discretisation)에서 발생한다고 가정할 수 있으므로, 더 많은 구조를 갖습니다. 따라서 $Ω$와 동일한 물체를 $T$로 나타내는 좌표 $\\mathbf{X}'$과 노드 수가 $n'$인 다른 메시 $\\mathcal{T' = (V' , E' , F' )}$을 가질 수 있습니다. 중요한 것은 메쉬 $\\mathcal{T}$와 $\\mathcal{T}'$은 서로 다른 연결 구조를 가질 수 있고, 심지어 노드 수도 다를 수 있다는 것입니다$(n' \\neq n)$. 따라서 이러한 메쉬를 단순히 노드를 재배열한 동형(isomorphic) 그래프로 생각할 수 없으며 순열 행렬(permutation matrix) $\\mathbf{P}$를 이들 간의 대응으로 간주합니다.\n",
    "\n",
    "함수 맵은 두 영역의 점(points) 사이의 대응(맵 $η : Ω → Ω'$)을 함수(functions) 사이의 대응(map $\\mathbf{C} : \\mathcal{X}(Ω) → \\mathcal{X}(Ω')$, 그림 13 참조)으로 대체하여 이러한 설정에 대한 대응 개념을 일반화한 것으로 Ovsjanikov 등(2012)에 의해 도입되었습니다. 함수 맵(functional map)은 선형 연산자 $\\mathbf{C}$로, $n' × n$ 행렬로 표현되며, 각 도메인에서 신호 $\\mathbf{x}'$과 $\\mathbf{x}$사이의 대응을 다음과 같이 설정합니다.\n",
    "\n",
    "$$\n",
    "    \\mathbf{x' = Cx}. \n",
    "$$\n",
    "\n",
    "루스타모프 (2013)은 면적 보존(area-preserving) 매핑을 보장하기 위해 함수 맵이 직교, 즉 $\\mathbf{C^{\\intercal}C = I}$, 즉 직교 그룹 $\\mathbf{C} ∈ O(n)$의 원소여야 한다는 것을 보여주었습니다. 이 경우 $C^{-1} = C^{\\intercal}$를 사용하여 맵을 반전(invert)시킬 수 있습니다.\n",
    "\n",
    ">대부분의 경우 함수 맵은 스펙트럼 영역에서 푸리에 계수 사이의 $k × k$ 맵 $\\hat{\\mathbf{C}}$로 구현되며, $x' = Φ'\\hat{\\mathbf{C}}Φ^{\\intercal}x$, 여기서 $Φ$ 및 $Φ'$ 은 (잘린(truncated)) 라플라시안 고유 기저(Laplacian eigenbases)의 각 $n × k$ 및 $n' × k$ 행렬이며, $k   \\ll n, n'$ 입니다.\n",
    "\n",
    "함수 맵은 또한 메시의 연산자 표현 간의 관계를 설정합니다,\n",
    "\n",
    "$$\n",
    "    \\mathbf{Q' = CQC^{\\intercal}, Q = C^{\\intercal}Q'C},\n",
    "$$\n",
    "\n",
    "다음과 같이 해석할 수 있습니다: $\\mathcal{T}$의 연산자 표현 $\\mathbf{Q}$와 함수 맵 $\\mathbf{C}$가 주어지면, 먼저 신호를 $\\mathcal{T}'$에서 $\\mathcal{T}$로 매핑하고 ($\\mathbf{C}^{\\intercal}$ 사용), 연산자 $\\mathbf{Q}$를 적용한 다음, 다시 $\\mathcal{T}'$ 으로 매핑하여 ($\\mathbf{C}$ 사용), $\\mathcal{T}'$ 의 표현 $\\mathbf{Q}'$을 구성할 수 있습니다. 이것은 모든 $\\mathbf{C} ∈ O(n)$에서 재메싱에서 불변(remeshing invariant) (또는 등변(equivariant)) 함수를 보다 일반적인 클래스로 이어지며, 다음을 만족합니다.\n",
    "\n",
    "$$\n",
    "    f(\\mathbf{Q}) = f(\\mathbf{CQC}^{\\intercal}) = f(\\mathbf{Q}')\n",
    "\\\\\n",
    "    \\mathbf{CF(Q) = F(CQC^{\\intercal}) = F(Q0')}\n",
    "$$\n",
    "앞서 설명한 순열 불변성(permutation invariance)과 동등성(equivariance) 설정은 노드의 순서만 변경하는 사소한 리메싱으로 생각할 수 있는 특수한 경우라는 것을 쉽게 알 수 있습니다.\n",
    "\n",
    ">이러한 연산을 오른쪽에서 왼쪽으로 읽는다는 점에 유의하세요.\n",
    "\n",
    ">이는 순열 행렬의 직교성$(P^{\\intercal}P = I)$에 따른 것입니다.\n",
    "\n",
    "Wang 등(2019a)은 연산자 $\\mathbf{Q = VΛV^{\\intercal}}$의 고유분해(eigendecomposition)가 주어지면, 모든 리메싱 불변(또는 등변) 함수는 $f(\\mathbf{Q}) = f(\\mathbf{Λ})$ 및 $\\mathbf{F(Q) = VF(Λ)}$로 표현될 수 있으며, 즉 리메싱 불변(remeshing-invariant) 함수는 $\\mathbf{Q}$의 스펙트럼만 포함한다는 것을 보여주었습니다. 실제로 라플라스 고유값 함수는 표면 이산화(surface discretisation) 및 섭동(perturbation)에 강하다는 것이 실제로 입증되었으며, 이는 컴퓨터 그래픽과 그래프에 대한 딥 러닝에서 라플라스에 기반한 스펙트럼 구성의 인기를 설명해줍니다(Defferrard et al, 2016; Levie 외., 2018). 이 결과는 일반적인 연산자 $\\mathbf{Q}$를 참조하기 때문에, 유비쿼터스 라플라스 연산자 외에도 다양한 선택이 가능합니다. 주목할 만한 예로는 Dirac(Liu et al., 2017; Kostrikov et al., 2018) 또는 Steklov(Wang et al., 2018) 연산자, 학습 가능한 파라메트릭 연산자(Wang et al., 2019a) 등이 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:13:39) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bcfaf3da971f87b91721743b1e9712a94e5baf8041af4e0a049618a6443e430e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
