{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43417c-5122-4729-9870-3b633dbd5eaf",
   "metadata": {},
   "source": [
    "# Pooling Architecture Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bbb158-e680-4c07-befb-eb4ed979544a",
   "metadata": {},
   "source": [
    "* [paper](https://arxiv.org/pdf/2108.10587.pdf)\n",
    "* [technical report](https://github.com/LARS-research/PAS-OGB/raw/main/report/PAS_OGB.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5008467d-16b3-4e87-a628-371f8508e25c",
   "metadata": {},
   "source": [
    "The paper presents a novel framework called Pooling Architecture Search (PAS), which is based on Neural Architecture Search (NAS) to search for adaptive architectures for graph classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a09a37-9ed0-46e0-be22-43e7afbb1316",
   "metadata": {},
   "source": [
    "The Design of the Search Space\r\n",
    "\r\n",
    "- 2 layers\r\n",
    "- 6 types of Aggregation Module\r\n",
    "    - GCN, GAT, GIN, MF, Transformer, and DeeperGCN\r\n",
    "- 3 Pooling Module\r\n",
    "    - TOPKPOOL, SAGPOOL, and ASAP\r\n",
    "    - The pooling layer is slightly redundant for smaller graphs, and the result of adding pooling layer is not good after testing. Therefore, we delete the search of pooling layer here.\r\n",
    "- 3 Readout Module\r\n",
    "    - GLOBAL_MEAN, GLOBAL_MAX, and GLOBAL_SUM.\r\n",
    "- 5 Merge Module\r\n",
    "    - M_LSTM, M_CONCAT, M_MAX, M_MEAN, and M_SUM        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8970fbf4-44dc-4245-9458-7f5fbb0ff392",
   "metadata": {},
   "source": [
    "on dataset\r\n",
    "* ogbg-molhiv\r\n",
    "    * the small scale -> cancel the search of pooling and merge operations.\r\n",
    "    * use heterogeneous interpolation process as a means of data enhancement\r\n",
    "* ogbg-molpcba\r\n",
    "    * the small scale -> cancel the search of pooling and merge operations\r\n",
    "* ogbg-ppa\r\n",
    "    * complete PAS search framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62937ae-3dba-4004-ab29-042929314e10",
   "metadata": {},
   "source": [
    "## Differentiable Search Algorithm\n",
    "\n",
    "The differentiable search algorithm is a key component of the Pooling Architecture Search (PAS) framework. It is designed to enable efficient search on top of the search space. **The algorithm relaxes the discrete search space into a continuous one by mixing the output of all candidate operations. This is achieved by a coarsening strategy designed to properly relax the selection of pooling operations in a continuous manner.**\n",
    "\r\n",
    "\r\n",
    "The algorithm constructs a supernet representing the search space for a 2-layer architecture backbone consisting of several modules. Each node in the supernet denotes the representations and each edge represents one operation from the corresponding sets. The discrete selection of operation in each module is relaxed by a weighted summation of all possible operations.\r\n",
    "\r\n",
    "The algorithm also includes optimization by gradient descent. Based on the mixed results of each module in the supernet, the prediction can be calculated by a classifier. The cross-entropy loss on training data is calculated and optim\n",
    "\n",
    "### Pros\r\n",
    "- **Efficiency**: The differentiable search algorithm is efficient as it enables the use of gradient descent for optimization. This reduces the search time by two orders of magnitude compared to reinforcement learning-based methods.\r\n",
    "- **Flexibility**: The algorithm is flexible as it relaxes the discrete search space into a continuous one. This allows for a more comprehensive exploration of the search space.\r\n",
    "- **Scalability**: The algorithm is scalable as it constructs a supernet representing the search space. This allows for the efficient handling of large search spaces.\r\n",
    "\r\n",
    "### Cons\r\n",
    "- **Complexity**: The differentiable search algorithm can be complex to implement due to the need for a coarsening strategy to relax the selection of operations.\r\n",
    "- **Dependency on the Search Space**: The performance of the algorithm is highly dependent on the design of the search space. A poorly designed search space may lead to suboptimal results.\r\n",
    "- **Requirement for Sufficient Training Data**: The algorithm requires sufficient training data to effectively optimize the cross-entropy loss.ized."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
